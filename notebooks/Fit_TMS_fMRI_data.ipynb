{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c977056a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Fit_TMS_fMRI_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup cell ---\n",
    "\n",
    "# 1ï¸âƒ£ Mount Google Drive (for data)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# 2ï¸âƒ£ Clone GitHub repository (for code)\n",
    "import os, sys, subprocess\n",
    "\n",
    "repo_dir = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
    "else:\n",
    "    print(\"Repo already exists âœ…\")\n",
    "\n",
    "# 3ï¸âƒ£ Define paths (TMS-fMRI)\n",
    "data_dir = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
    "preproc_dir = os.path.join(data_dir, \"preprocessed_subjects_tms_fmri\")\n",
    "\n",
    "# Where to save training outputs (kept separate from HCP)\n",
    "weights_dir = os.path.join(preproc_dir, \"trained_models_MLP_tms_fmri\")\n",
    "ects_dir    = os.path.join(preproc_dir, \"ECts_MLP_tms_fmri\")  # keep naming consistent with your convention\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "os.makedirs(ects_dir, exist_ok=True)\n",
    "\n",
    "# 4ï¸âƒ£ Add repo to import path + imports\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src import NPI\n",
    "from src.preprocessing_tms_fmri import split_last_fraction, make_inputs_targets\n",
    "\n",
    "import gc\n",
    "\n",
    "# 5ï¸âƒ£ Check device\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"âš ï¸  GPU not detected â€” training will run on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c16119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training parameters ---\n",
    "\n",
    "# Choose ANN architecture: 'MLP', 'CNN', 'RNN', or 'VAR'\n",
    "method = \"MLP\"\n",
    "\n",
    "# Data / model hyperparameters\n",
    "ROI_num = 450         # Tian 50 + Schaefer 400\n",
    "using_steps = 3       # S: number of past steps used to predict next step\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 5e-4\n",
    "l2_reg = 5e-5\n",
    "\n",
    "# Population split rule (fixed): last 10% within each participant is test\n",
    "test_fraction = 0.10\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Dataset: TMS-fMRI (task-rest only), population model\")\n",
    "print(f\"  Method: {method}\")\n",
    "print(f\"  Regions: {ROI_num}\")\n",
    "print(f\"  Steps: {using_steps}\")\n",
    "print(f\"  Test fraction (per-subject): {test_fraction}\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2632e",
   "metadata": {},
   "source": [
    "\n",
    "### Notes on the split (important)\n",
    "\n",
    "We **do not** concatenate raw time series across participants.\n",
    "\n",
    "Instead:\n",
    "1. For each participant, we split the **filtered signals** into train/test by taking the **last 10%** as test.\n",
    "2. We create **Inputs/Targets within each split**, so no sample ever crosses a subject boundary.\n",
    "3. We then concatenate **samples** across participants to form population train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d37b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Build population train/test datasets from per-subject signals ---\n",
    "\n",
    "import glob\n",
    "\n",
    "signal_files = sorted(glob.glob(os.path.join(preproc_dir, \"sub-*_signals.npy\")))\n",
    "if len(signal_files) == 0:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No *_signals.npy found in {preproc_dir}. \"\n",
    "        \"Run Process_TMS_fMRI_data.ipynb first (task-rest).\"\n",
    "    )\n",
    "\n",
    "subject_ids = [os.path.basename(f).replace(\"_signals.npy\", \"\") for f in signal_files]\n",
    "print(f\"Found {len(subject_ids)} subjects with signals.\")\n",
    "\n",
    "X_train_list, Y_train_list = [], []\n",
    "X_test_list,  Y_test_list  = [], []\n",
    "\n",
    "for sid in subject_ids:\n",
    "    signals = np.load(os.path.join(preproc_dir, f\"{sid}_signals.npy\"))  # (T, 450)\n",
    "\n",
    "    # Split last 10% test within subject\n",
    "    sig_train, sig_test = split_last_fraction(signals, test_fraction=test_fraction)\n",
    "\n",
    "    # Build Inputs/Targets within each split\n",
    "    Xtr, Ytr = make_inputs_targets(sig_train, steps=using_steps)\n",
    "    Xte, Yte = make_inputs_targets(sig_test,  steps=using_steps)\n",
    "\n",
    "    # Some subjects may have too-short test splits; skip empty ones safely\n",
    "    if Xtr.shape[0] > 0:\n",
    "        X_train_list.append(Xtr); Y_train_list.append(Ytr)\n",
    "    if Xte.shape[0] > 0:\n",
    "        X_test_list.append(Xte);  Y_test_list.append(Yte)\n",
    "\n",
    "    print(sid, \"| signals:\", signals.shape, \"| train samples:\", Xtr.shape[0], \"| test samples:\", Xte.shape[0])\n",
    "\n",
    "# Concatenate samples across subjects\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "Y_train = np.concatenate(Y_train_list, axis=0)\n",
    "X_test  = np.concatenate(X_test_list, axis=0) if len(X_test_list) else np.zeros((0, using_steps * ROI_num), dtype=np.float32)\n",
    "Y_test  = np.concatenate(Y_test_list, axis=0) if len(Y_test_list) else np.zeros((0, ROI_num), dtype=np.float32)\n",
    "\n",
    "print(\"\\nPopulation dataset shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"Y_train:\", Y_train.shape)\n",
    "print(\"  X_test: \", X_test.shape,  \"Y_test: \", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45feaec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train population model with a fixed (external) test set ---\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_NN_fixed_test(\n",
    "    model: nn.Module,\n",
    "    X_train: np.ndarray,\n",
    "    Y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    Y_test: np.ndarray,\n",
    "    batch_size: int = 64,\n",
    "    num_epochs: int = 50,\n",
    "    lr: float = 5e-4,\n",
    "    l2: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a model on (X_train,Y_train) and evaluate on (X_test,Y_test) each epoch.\n",
    "    Mirrors NPI.train_NN style but avoids re-splitting internally.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    train_inputs  = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    train_targets = torch.tensor(Y_train, dtype=torch.float32, device=device)\n",
    "\n",
    "    test_inputs  = torch.tensor(X_test, dtype=torch.float32, device=device) if X_test.size else None\n",
    "    test_targets = torch.tensor(Y_test, dtype=torch.float32, device=device) if Y_test.size else None\n",
    "\n",
    "    n_train = train_inputs.shape[0]\n",
    "    train_epoch_loss, test_epoch_loss = [], []\n",
    "\n",
    "    for ep in range(num_epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(n_train, device=device)\n",
    "        ep_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for i in range(0, n_train, batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            xb = train_inputs[idx]\n",
    "            yb = train_targets[idx]\n",
    "\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            ep_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        train_epoch_loss.append(ep_loss / max(1, n_batches))\n",
    "\n",
    "        # test\n",
    "        if test_inputs is not None and test_inputs.shape[0] > 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(test_inputs)\n",
    "                tloss = loss_fn(pred, test_targets).item()\n",
    "            test_epoch_loss.append(tloss)\n",
    "        else:\n",
    "            test_epoch_loss.append(float(\"nan\"))\n",
    "\n",
    "        if (ep + 1) % 5 == 0 or ep == 0:\n",
    "            print(f\"Epoch {ep+1:3d}/{num_epochs} | train={train_epoch_loss[-1]:.6f} | test={test_epoch_loss[-1]:.6f}\")\n",
    "\n",
    "    return model, train_epoch_loss, test_epoch_loss\n",
    "\n",
    "# Build model using existing NPI helper\n",
    "model = NPI.build_model(method, ROI_num, using_steps)\n",
    "\n",
    "model, train_loss, test_loss = train_NN_fixed_test(\n",
    "    model,\n",
    "    X_train, Y_train,\n",
    "    X_test, Y_test,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    lr=learning_rate,\n",
    "    l2=l2_reg,\n",
    ")\n",
    "\n",
    "print(\"âœ… Training complete | Final test loss:\", test_loss[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d847ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Save model + results (TMS-fMRI population) ---\n",
    "\n",
    "import os, json\n",
    "\n",
    "model_path = os.path.join(weights_dir, f\"population_{method}_tms_fmri.pt\")\n",
    "torch.save(model, model_path)\n",
    "\n",
    "results = {\n",
    "    \"dataset\": \"TMS-fMRI task-rest (population)\",\n",
    "    \"method\": method,\n",
    "    \"ROI_num\": ROI_num,\n",
    "    \"using_steps\": using_steps,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"l2_reg\": l2_reg,\n",
    "    \"test_fraction_per_subject\": test_fraction,\n",
    "    \"n_subjects\": len(subject_ids),\n",
    "    \"n_train_samples\": int(X_train.shape[0]),\n",
    "    \"n_test_samples\": int(X_test.shape[0]),\n",
    "    \"model_path\": model_path,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"test_loss\": test_loss,\n",
    "}\n",
    "\n",
    "results_path = os.path.join(preproc_dir, f\"ANN_results_{method}_tms_fmri_population.json\")\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"ðŸ’¾ Saved model:\", model_path)\n",
    "print(\"ðŸ’¾ Saved results:\", results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd595ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Visualize learning curves ---\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.plot(test_loss, label=\"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE loss\")\n",
    "plt.legend()\n",
    "plt.title(f\"Population {method} | TMS-fMRI task-rest\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
