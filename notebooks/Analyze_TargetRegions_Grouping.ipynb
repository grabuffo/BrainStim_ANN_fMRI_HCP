{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6fcad5",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Analyze_TargetRegions_Grouping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491379e",
   "metadata": {},
   "source": [
    "# Analyze Target Regions & Group Participants by Stimulation Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4fb40",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "1. Loads the TMS-fMRI dataset\n",
    "2. Extracts target regions for each subject's task-stim sessions\n",
    "3. Groups participants by target region\n",
    "4. Provides summary statistics on group sizes and target region distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup cell (Google Colab compatibility) ---\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    BASE = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    # Local path\n",
    "    BASE = \"/path/to/your/data\"  # Update this if running locally\n",
    "\n",
    "# Clone repo if needed\n",
    "if IN_COLAB:\n",
    "    repo_dir = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
    "    if not os.path.exists(repo_dir):\n",
    "        !git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
    "    else:\n",
    "        print(\"Repo already exists âœ…\")\n",
    "    sys.path.append(repo_dir)\n",
    "\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "print(f\"Data directory: {BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d295a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load dataset ---\n",
    "\n",
    "DATASET_PKL = os.path.join(BASE, \"TMS_fMRI\", \"dataset_tian50_schaefer400_allruns.pkl\")\n",
    "\n",
    "print(f\"Loading dataset from: {DATASET_PKL}\")\n",
    "with open(DATASET_PKL, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully\")\n",
    "print(f\"Number of subjects: {len(dataset)}\")\n",
    "print(f\"Sample subject keys: {list(dataset.keys())[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e08ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract subject list and explore structure ---\n",
    "\n",
    "subjects_list = sorted([s.replace('sub-', '') for s in dataset.keys()])\n",
    "print(f\"Subjects: {subjects_list}\")\n",
    "print(f\"Total subjects: {len(subjects_list)}\")\n",
    "\n",
    "# Check structure for first subject\n",
    "first_subject = 'sub-' + subjects_list[0]\n",
    "print(f\"\\nStructure for {first_subject}:\")\n",
    "print(f\"  Conditions: {list(dataset[first_subject].keys())}\")\n",
    "print(f\"  Task-rest trials: {len(dataset[first_subject].get('task-rest', []))}\")\n",
    "print(f\"  Task-stim trials: {len(dataset[first_subject].get('task-stim', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7540b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract target regions for each subject ---\n",
    "\n",
    "# Dictionary: subject_id -> list of target region IDs (from task-stim sessions)\n",
    "subject_targets = {}\n",
    "\n",
    "# Dictionary: target_region_id -> list of subject_ids\n",
    "target_to_subjects = defaultdict(list)\n",
    "\n",
    "# Track all unique target regions\n",
    "all_target_regions = set()\n",
    "\n",
    "for subject_id, subject_name in enumerate(subjects_list):\n",
    "    full_subject_name = 'sub-' + subject_name\n",
    "    \n",
    "    # Get task-stim sessions for this subject\n",
    "    task_stim_sessions = dataset[full_subject_name].get('task-stim', [])\n",
    "    \n",
    "    subject_targets[subject_id] = []\n",
    "    \n",
    "    # Extract target region from each task-stim session\n",
    "    for trial in range(len(task_stim_sessions)):\n",
    "        try:\n",
    "            target_array = dataset[full_subject_name]['task-stim'][trial]['target']\n",
    "            target_id = np.where(target_array == 1)[0][0]\n",
    "            subject_targets[subject_id].append(target_id)\n",
    "            all_target_regions.add(target_id)\n",
    "            target_to_subjects[target_id].append(subject_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting target for {full_subject_name} trial {trial}: {e}\")\n",
    "\n",
    "print(f\"âœ… Target regions extracted\")\n",
    "print(f\"\\nTotal unique target regions: {len(all_target_regions)}\")\n",
    "print(f\"Target region IDs: {sorted(all_target_regions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d485df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary: targets per subject ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TARGET REGIONS PER SUBJECT\")\n",
    "print(\"=\"*60)\n",
    "for subject_id, subject_name in enumerate(subjects_list):\n",
    "    targets = subject_targets[subject_id]\n",
    "    unique_targets = set(targets)\n",
    "    print(f\"Subject {subject_id:2d} ({subject_name:3s}): {list(unique_targets)} (n_sessions={len(targets)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary: participants per target region ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PARTICIPANTS PER TARGET REGION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a clean summary\n",
    "target_region_summary = {}\n",
    "for target_id in sorted(all_target_regions):\n",
    "    subject_ids = sorted(list(set(target_to_subjects[target_id])))  # unique subjects per target\n",
    "    n_subjects = len(subject_ids)\n",
    "    subject_names = [subjects_list[sid] for sid in subject_ids]\n",
    "    target_region_summary[target_id] = {\n",
    "        'subject_ids': subject_ids,\n",
    "        'subject_names': subject_names,\n",
    "        'n_subjects': n_subjects,\n",
    "        'n_sessions': len(target_to_subjects[target_id])\n",
    "    }\n",
    "    print(f\"Target region {target_id:3d}: {n_subjects} subjects {subject_names} ({len(target_to_subjects[target_id])} sessions total)\")\n",
    "\n",
    "print(f\"\\nTotal groups: {len(target_region_summary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization: Histogram of group sizes ---\n",
    "\n",
    "group_sizes = [info['n_subjects'] for info in target_region_summary.values()]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(group_sizes, bins=range(1, max(group_sizes)+2), edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.set_xlabel('Number of participants per target region')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Group Sizes')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Bar plot: participants per target region\n",
    "target_ids = sorted(target_region_summary.keys())\n",
    "n_subjects_per_target = [target_region_summary[tid]['n_subjects'] for tid in target_ids]\n",
    "\n",
    "colors = ['steelblue' if n >= 2 else 'lightcoral' for n in n_subjects_per_target]\n",
    "ax2.bar(range(len(target_ids)), n_subjects_per_target, color=colors, edgecolor='black', alpha=0.7)\n",
    "ax2.set_xlabel('Target Region ID')\n",
    "ax2.set_ylabel('Number of participants')\n",
    "ax2.set_title('Participants per Target Region')\n",
    "ax2.set_xticks(range(len(target_ids)))\n",
    "ax2.set_xticklabels([str(tid) for tid in target_ids], rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.axhline(y=2, color='red', linestyle='--', linewidth=1.5, alpha=0.5, label='Min for group')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ’¡ Note: Blue bars = targets with â‰¥2 participants (can form groups)\")\n",
    "print(f\"           Red bars = targets with 1 participant (singleton groups)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6023e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Statistical summary ---\n",
    "\n",
    "group_sizes = np.array([info['n_subjects'] for info in target_region_summary.values()])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total target regions: {len(target_region_summary)}\")\n",
    "print(f\"Mean participants per group: {group_sizes.mean():.2f}\")\n",
    "print(f\"Median participants per group: {np.median(group_sizes):.0f}\")\n",
    "print(f\"Min participants per group: {group_sizes.min()}\")\n",
    "print(f\"Max participants per group: {group_sizes.max()}\")\n",
    "print(f\"\\nGroups with â‰¥2 participants: {(group_sizes >= 2).sum()}\")\n",
    "print(f\"Groups with 1 participant: {(group_sizes == 1).sum()}\")\n",
    "print(f\"\\nTotal participants to train: {(group_sizes >= 2).sum()} groups\")\n",
    "print(f\"Participants in multi-subject groups: {group_sizes[group_sizes >= 2].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create grouped participant list for downstream analysis ---\n",
    "\n",
    "# Filter to only groups with â‰¥2 participants (ready for training)\n",
    "multi_subject_groups = {target_id: info for target_id, info in target_region_summary.items() if info['n_subjects'] >= 2}\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Multi-subject groups ready for training:\")\n",
    "print(f\"=\"*60)\n",
    "for target_id, info in sorted(multi_subject_groups.items()):\n",
    "    print(f\"Target {target_id}: {info['n_subjects']} participants {info['subject_names']}\")\n",
    "\n",
    "print(f\"\\nâœ… Total trainable groups: {len(multi_subject_groups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72449455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: Save summary to pickle for downstream notebooks ---\n",
    "\n",
    "summary = {\n",
    "    'subjects_list': subjects_list,\n",
    "    'subject_targets': subject_targets,\n",
    "    'all_target_regions': sorted(list(all_target_regions)),\n",
    "    'target_region_summary': target_region_summary,\n",
    "    'multi_subject_groups': multi_subject_groups,\n",
    "}\n",
    "\n",
    "summary_pkl = os.path.join(BASE, \"TMS_fMRI\", \"target_regions_grouping_summary.pkl\")\n",
    "with open(summary_pkl, \"wb\") as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(f\"ðŸ’¾ Saved grouping summary to: {summary_pkl}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
