{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d289d08",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Validate_TMS_fMRI_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c67626",
   "metadata": {},
   "source": [
    "# Validate TMS-fMRI Simulations with Population ANN\n",
    "\n",
    "Comprehensive validation of synthetic TMS-fMRI data by comparing empirical vs. simulated connectivity patterns.\n",
    "\n",
    "## Validation Strategy\n",
    "\n",
    "### i) **Target-Seed Validation** (per target region)\n",
    "For each stimulated target region, compute seed-based FC (rest, stim, delta) correlations between empirical and simulated data.\n",
    "\n",
    "### ii) **All-Seeds Validation** (per target region, repeated for all 450 seeds)\n",
    "For each target region and each possible seed (450 ROIs), compute seed-FC correlations. Summarize:\n",
    "- Mean correlation for each seed\n",
    "- Statistical significance (p-value) for each seed\n",
    "- **Percentage of significant seeds** (how many seeds have r significantly > 0?)\n",
    "\n",
    "### iii) **Full FC Validation** (entire correlation matrices)\n",
    "Compare entire static FC and delta-FC matrices between empirical and simulated across all conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9c584",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f297787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, sys, pickle, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_1samp\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4e9a2",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9edb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
    "\n",
    "DATASET_EMP_PKL = os.path.join(BASE, \"TMS_fMRI\", \"dataset_tian50_schaefer400_allruns.pkl\")\n",
    "PREPROC_ROOT = os.path.join(BASE, \"preprocessed_subjects_tms_fmri\")\n",
    "OUT_DIR = os.path.join(PREPROC_ROOT, \"ANN_vs_tms_fmri\")\n",
    "\n",
    "DATASET_SIM_PKL = os.path.join(OUT_DIR, \"dataset_simulated_populationANN.pkl\")\n",
    "VALIDATION_RESULTS_JSON = os.path.join(OUT_DIR, \"validation_results_comprehensive.json\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Empirical dataset: {DATASET_EMP_PKL}\")\n",
    "print(f\"✓ Simulated dataset: {DATASET_SIM_PKL}\")\n",
    "print(f\"✓ Output: {VALIDATION_RESULTS_JSON}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eeee37",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading empirical dataset...\")\n",
    "with open(DATASET_EMP_PKL, \"rb\") as f:\n",
    "    dataset_emp = pickle.load(f)\n",
    "print(f\"✓ Loaded {len(dataset_emp)} subjects (empirical)\")\n",
    "\n",
    "print(\"\\nLoading simulated dataset...\")\n",
    "with open(DATASET_SIM_PKL, \"rb\") as f:\n",
    "    dataset_sim = pickle.load(f)\n",
    "print(f\"✓ Loaded {len(dataset_sim)} subjects (simulated)\")\n",
    "\n",
    "# Sanity check\n",
    "assert set(dataset_emp.keys()) == set(dataset_sim.keys()), \"Subject mismatch!\"\n",
    "print(f\"\\n✓ Subjects match across datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ddc3e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_target_idx(target_vec):\n",
    "    \"\"\"Extract target region index from one-hot vector.\"\"\"\n",
    "    if target_vec is None:\n",
    "        return None\n",
    "    v = np.asarray(target_vec).astype(int).ravel()\n",
    "    if v.size == 0 or v.sum() != 1:\n",
    "        return None\n",
    "    return int(np.argmax(v))\n",
    "\n",
    "def seed_based_fc(ts, seed_idx, all_regions=True):\n",
    "    \"\"\"Compute seed-based FC: correlation of seed with all other regions.\n",
    "    \n",
    "    Args:\n",
    "        ts: (T, N) time series\n",
    "        seed_idx: index of seed region\n",
    "        all_regions: if True use all 450 regions; if False use cortical only (400)\n",
    "    \n",
    "    Returns:\n",
    "        fc_seed: (N-1,) correlation vector (excluding seed's autocorrelation)\n",
    "    \"\"\"\n",
    "    if not all_regions:\n",
    "        ts = ts[:, 50:]  # Skip Tian 50, keep Schaefer 400\n",
    "        seed_idx = seed_idx - 50  # Adjust seed index\n",
    "    \n",
    "    if seed_idx < 0 or seed_idx >= ts.shape[1]:\n",
    "        return None\n",
    "    \n",
    "    seed_ts = ts[:, seed_idx]  # (T,)\n",
    "    # Correlate seed with all regions (including itself initially)\n",
    "    corrmat = np.corrcoef(seed_ts, ts.T)  # (1+N, 1+N)\n",
    "    fc_seed = corrmat[0, 1:]  # (N,) - correlations with all regions\n",
    "    return fc_seed\n",
    "\n",
    "def compute_fc_matrix(ts):\n",
    "    \"\"\"Compute full FC matrix from time series.\"\"\"\n",
    "    return np.corrcoef(ts.T).astype(np.float32)\n",
    "\n",
    "def upper_triangle_vec(mat, k=1):\n",
    "    \"\"\"Extract upper triangle as 1D vector.\"\"\"\n",
    "    iu = np.triu_indices(mat.shape[0], k=k)\n",
    "    return mat[iu]\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfc19b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part I: Target-Seed Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403c9e8",
   "metadata": {},
   "source": [
    "For each target region, validate using only that region as the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ba591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PART I: TARGET-SEED VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFor each target region, compute seed-FC correlations (empirical vs simulated)\")\n",
    "print(\"Conditions: REST, STIM, DELTA (stim - rest)\\n\")\n",
    "\n",
    "# Organize results by target\n",
    "target_seed_results = {}\n",
    "\n",
    "for sub_id in sorted(dataset_emp.keys()):\n",
    "    if sub_id not in dataset_sim:\n",
    "        continue\n",
    "    \n",
    "    sub_emp = dataset_emp[sub_id]\n",
    "    sub_sim = dataset_sim[sub_id]\n",
    "    \n",
    "    # --- REST condition (baseline) ---\n",
    "    rest_emp_list = []\n",
    "    rest_sim_list = []\n",
    "    \n",
    "    for run in sub_emp.get(\"task-rest\", {}).values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            rest_emp_list.append(ts)\n",
    "    \n",
    "    for run in sub_sim.get(\"task-rest\", {}).values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            rest_sim_list.append(ts)\n",
    "    \n",
    "    if not rest_emp_list or not rest_sim_list:\n",
    "        continue\n",
    "    \n",
    "    # Average across rest runs\n",
    "    rest_emp = np.concatenate(rest_emp_list, axis=0)\n",
    "    rest_sim = np.concatenate(rest_sim_list, axis=0)\n",
    "    \n",
    "    # Compute rest FC\n",
    "    fc_rest_emp = compute_fc_matrix(rest_emp)\n",
    "    fc_rest_sim = compute_fc_matrix(rest_sim)\n",
    "    \n",
    "    # --- STIM condition ---\n",
    "    stim_runs_emp = sub_emp.get(\"task-stim\", {})\n",
    "    stim_runs_sim = sub_sim.get(\"task-stim\", {})\n",
    "    \n",
    "    if not stim_runs_emp or not stim_runs_sim:\n",
    "        continue\n",
    "    \n",
    "    # Process each stim run\n",
    "    for run_idx, run_emp in stim_runs_emp.items():\n",
    "        run_sim = stim_runs_sim.get(run_idx)\n",
    "        if run_sim is None:\n",
    "            continue\n",
    "        \n",
    "        ts_emp = run_emp.get(\"time series\")\n",
    "        ts_sim = run_sim.get(\"time series\")\n",
    "        target_vec = run_emp.get(\"target\")\n",
    "        \n",
    "        if not isinstance(ts_emp, np.ndarray) or not isinstance(ts_sim, np.ndarray):\n",
    "            continue\n",
    "        if ts_emp.shape[1] < 450 or ts_sim.shape[1] < 450:\n",
    "            continue\n",
    "        \n",
    "        target_idx = safe_target_idx(target_vec)\n",
    "        if target_idx is None:\n",
    "            continue\n",
    "        \n",
    "        # Key: target region index\n",
    "        target_key = f\"target_{target_idx:03d}\"\n",
    "        \n",
    "        if target_key not in target_seed_results:\n",
    "            target_seed_results[target_key] = {\n",
    "                'target_idx': target_idx,\n",
    "                'correlations': []\n",
    "            }\n",
    "        \n",
    "        # Compute seed-based FC using target as seed\n",
    "        fc_seed_rest_emp = seed_based_fc(rest_emp, target_idx, all_regions=True)\n",
    "        fc_seed_rest_sim = seed_based_fc(rest_sim, target_idx, all_regions=True)\n",
    "        \n",
    "        fc_seed_stim_emp = seed_based_fc(ts_emp, target_idx, all_regions=True)\n",
    "        fc_seed_stim_sim = seed_based_fc(ts_sim, target_idx, all_regions=True)\n",
    "        \n",
    "        if fc_seed_rest_emp is None or fc_seed_stim_emp is None:\n",
    "            continue\n",
    "        \n",
    "        # Correlate seed-FC vectors\n",
    "        r_rest = np.corrcoef(fc_seed_rest_emp, fc_seed_rest_sim)[0, 1]\n",
    "        r_stim = np.corrcoef(fc_seed_stim_emp, fc_seed_stim_sim)[0, 1]\n",
    "        \n",
    "        # Delta: stimulation-induced change\n",
    "        delta_emp = fc_seed_stim_emp - fc_seed_rest_emp\n",
    "        delta_sim = fc_seed_stim_sim - fc_seed_rest_sim\n",
    "        r_delta = np.corrcoef(delta_emp, delta_sim)[0, 1]\n",
    "        \n",
    "        target_seed_results[target_key]['correlations'].append({\n",
    "            'subject': sub_id,\n",
    "            'r_rest': float(r_rest),\n",
    "            'r_stim': float(r_stim),\n",
    "            'r_delta': float(r_delta),\n",
    "        })\n",
    "\n",
    "print(f\"\\n✓ Computed target-seed correlations for {len(target_seed_results)} target regions\")\n",
    "print(f\"\\nPer-target summary (first 5 targets):\")\n",
    "for target_key in sorted(target_seed_results.keys())[:5]:\n",
    "    n_corrs = len(target_seed_results[target_key]['correlations'])\n",
    "    print(f\"  {target_key}: {n_corrs} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95cf918",
   "metadata": {},
   "source": [
    "### Part I Results: Target-Seed Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dba680",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TARGET-SEED VALIDATION: SUMMARY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "summary_by_condition = {\n",
    "    'rest': [],\n",
    "    'stim': [],\n",
    "    'delta': []\n",
    "}\n",
    "\n",
    "target_summary_table = []\n",
    "\n",
    "for target_key in sorted(target_seed_results.keys()):\n",
    "    corrs = target_seed_results[target_key]['correlations']\n",
    "    \n",
    "    r_rest_vals = np.array([c['r_rest'] for c in corrs if np.isfinite(c['r_rest'])])\n",
    "    r_stim_vals = np.array([c['r_stim'] for c in corrs if np.isfinite(c['r_stim'])])\n",
    "    r_delta_vals = np.array([c['r_delta'] for c in corrs if np.isfinite(c['r_delta'])])\n",
    "    \n",
    "    summary_by_condition['rest'].extend(r_rest_vals)\n",
    "    summary_by_condition['stim'].extend(r_stim_vals)\n",
    "    summary_by_condition['delta'].extend(r_delta_vals)\n",
    "    \n",
    "    target_summary_table.append({\n",
    "        'Target': target_key,\n",
    "        'N': len(corrs),\n",
    "        'Mean_r_rest': r_rest_vals.mean() if len(r_rest_vals) > 0 else np.nan,\n",
    "        'Mean_r_stim': r_stim_vals.mean() if len(r_stim_vals) > 0 else np.nan,\n",
    "        'Mean_r_delta': r_delta_vals.mean() if len(r_delta_vals) > 0 else np.nan,\n",
    "        'Std_r_delta': r_delta_vals.std() if len(r_delta_vals) > 0 else np.nan,\n",
    "    })\n",
    "\n",
    "df_targets = pd.DataFrame(target_summary_table)\n",
    "print(df_targets.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POOLED ACROSS ALL TARGETS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for condition in ['rest', 'stim', 'delta']:\n",
    "    data = np.array(summary_by_condition[condition])\n",
    "    data = data[np.isfinite(data)]\n",
    "    t_stat, t_p = ttest_1samp(data, 0) if len(data) > 0 else (np.nan, np.nan)\n",
    "    \n",
    "    print(f\"\\n{condition.upper()} condition:\")\n",
    "    print(f\"  N observations: {len(data)}\")\n",
    "    print(f\"  Mean r: {data.mean():.4f} ± {data.std():.4f}\")\n",
    "    print(f\"  Range: [{data.min():.4f}, {data.max():.4f}]\")\n",
    "    print(f\"  t-test p-value: {t_p:.6f}\")\n",
    "    print(f\"  Significant? {'YES' if t_p < 0.05 else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5e39d",
   "metadata": {},
   "source": [
    "---\n",
    "# Part II: All-Seeds Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710444da",
   "metadata": {},
   "source": [
    "For each target region, repeat the analysis using ALL 450 regions as seeds. Calculate:\n",
    "- Correlation for each seed\n",
    "- Significance (p-value) for each seed\n",
    "- **% of seeds with significant correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ee8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART II: ALL-SEEDS VALIDATION (PER TARGET REGION)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFor each target region, compute seed-FC for all 450 seeds.\")\n",
    "print(\"Calculate significance and % significant seeds.\\n\")\n",
    "\n",
    "all_seeds_results = {}\n",
    "\n",
    "# Compute global rest FC (across all subjects/runs)\n",
    "print(\"Computing global rest FC matrices...\")\n",
    "rest_emp_all = []\n",
    "rest_sim_all = []\n",
    "\n",
    "for sub_id in sorted(dataset_emp.keys()):\n",
    "    for run in dataset_emp[sub_id].get(\"task-rest\", {}).values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            rest_emp_all.append(ts)\n",
    "    \n",
    "    for run in dataset_sim[sub_id].get(\"task-rest\", {}).values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            rest_sim_all.append(ts)\n",
    "\n",
    "rest_emp_concat = np.concatenate(rest_emp_all, axis=0)\n",
    "rest_sim_concat = np.concatenate(rest_sim_all, axis=0)\n",
    "print(f\"  Empirical rest: {rest_emp_concat.shape}\")\n",
    "print(f\"  Simulated rest: {rest_sim_concat.shape}\")\n",
    "\n",
    "# --- Now iterate over targets ---\n",
    "for sub_id in sorted(dataset_emp.keys()):\n",
    "    if sub_id not in dataset_sim:\n",
    "        continue\n",
    "    \n",
    "    stim_runs_emp = dataset_emp[sub_id].get(\"task-stim\", {})\n",
    "    stim_runs_sim = dataset_sim[sub_id].get(\"task-stim\", {})\n",
    "    \n",
    "    for run_idx, run_emp in stim_runs_emp.items():\n",
    "        run_sim = stim_runs_sim.get(run_idx)\n",
    "        if run_sim is None:\n",
    "            continue\n",
    "        \n",
    "        ts_emp = run_emp.get(\"time series\")\n",
    "        ts_sim = run_sim.get(\"time series\")\n",
    "        target_vec = run_emp.get(\"target\")\n",
    "        \n",
    "        if not isinstance(ts_emp, np.ndarray) or not isinstance(ts_sim, np.ndarray):\n",
    "            continue\n",
    "        if ts_emp.shape[1] < 450 or ts_sim.shape[1] < 450:\n",
    "            continue\n",
    "        \n",
    "        target_idx = safe_target_idx(target_vec)\n",
    "        if target_idx is None:\n",
    "            continue\n",
    "        \n",
    "        target_key = f\"target_{target_idx:03d}\"\n",
    "        \n",
    "        if target_key not in all_seeds_results:\n",
    "            all_seeds_results[target_key] = {\n",
    "                'target_idx': target_idx,\n",
    "                'seed_results': {}\n",
    "            }\n",
    "        \n",
    "        # For each of 450 seeds, compute correlation\n",
    "        for seed_idx in range(450):\n",
    "            fc_seed_rest_emp = seed_based_fc(rest_emp_concat, seed_idx, all_regions=True)\n",
    "            fc_seed_rest_sim = seed_based_fc(rest_sim_concat, seed_idx, all_regions=True)\n",
    "            \n",
    "            fc_seed_stim_emp = seed_based_fc(ts_emp, seed_idx, all_regions=True)\n",
    "            fc_seed_stim_sim = seed_based_fc(ts_sim, seed_idx, all_regions=True)\n",
    "            \n",
    "            if fc_seed_rest_emp is None or fc_seed_stim_emp is None:\n",
    "                continue\n",
    "            \n",
    "            # REST correlation\n",
    "            r_rest = np.corrcoef(fc_seed_rest_emp, fc_seed_rest_sim)[0, 1]\n",
    "            \n",
    "            # STIM correlation\n",
    "            r_stim = np.corrcoef(fc_seed_stim_emp, fc_seed_stim_sim)[0, 1]\n",
    "            \n",
    "            # DELTA correlation\n",
    "            delta_emp = fc_seed_stim_emp - fc_seed_rest_emp\n",
    "            delta_sim = fc_seed_stim_sim - fc_seed_rest_sim\n",
    "            r_delta = np.corrcoef(delta_emp, delta_sim)[0, 1]\n",
    "            \n",
    "            seed_key = f\"seed_{seed_idx:03d}\"\n",
    "            if seed_key not in all_seeds_results[target_key]['seed_results']:\n",
    "                all_seeds_results[target_key]['seed_results'][seed_key] = []\n",
    "            \n",
    "            all_seeds_results[target_key]['seed_results'][seed_key].append({\n",
    "                'subject': sub_id,\n",
    "                'r_rest': float(r_rest),\n",
    "                'r_stim': float(r_stim),\n",
    "                'r_delta': float(r_delta),\n",
    "            })\n",
    "\n",
    "print(f\"\\n✓ Computed all-seeds correlations for {len(all_seeds_results)} target regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78686b",
   "metadata": {},
   "source": [
    "### Part II Results: Per-Target Statistics with % Significant Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL-SEEDS VALIDATION: RESULTS PER TARGET REGION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "target_seeds_summary = []\n",
    "\n",
    "for target_key in sorted(all_seeds_results.keys()):\n",
    "    target_data = all_seeds_results[target_key]\n",
    "    seed_results_dict = target_data['seed_results']\n",
    "    \n",
    "    all_r_delta = []\n",
    "    significant_count = 0\n",
    "    total_seeds = 0\n",
    "    \n",
    "    for seed_key in sorted(seed_results_dict.keys()):\n",
    "        seed_corrs = seed_results_dict[seed_key]\n",
    "        \n",
    "        # Pool correlations across subjects/runs for this seed\n",
    "        r_delta_vals = np.array([c['r_delta'] for c in seed_corrs if np.isfinite(c['r_delta'])])\n",
    "        \n",
    "        if len(r_delta_vals) == 0:\n",
    "            continue\n",
    "        \n",
    "        all_r_delta.extend(r_delta_vals)\n",
    "        total_seeds += 1\n",
    "        \n",
    "        # Test if mean r_delta significantly > 0\n",
    "        t_stat, p_val = ttest_1samp(r_delta_vals, 0)\n",
    "        if p_val < 0.05:\n",
    "            significant_count += 1\n",
    "    \n",
    "    pct_significant = (significant_count / total_seeds * 100) if total_seeds > 0 else 0\n",
    "    all_r_delta = np.array(all_r_delta)\n",
    "    \n",
    "    target_seeds_summary.append({\n",
    "        'Target': target_key,\n",
    "        'N_seeds': total_seeds,\n",
    "        'Mean_r_delta': all_r_delta.mean() if len(all_r_delta) > 0 else np.nan,\n",
    "        'Std_r_delta': all_r_delta.std() if len(all_r_delta) > 0 else np.nan,\n",
    "        'Sig_seeds_count': significant_count,\n",
    "        'Pct_significant': pct_significant,\n",
    "    })\n",
    "\n",
    "df_seeds_summary = pd.DataFrame(target_seeds_summary)\n",
    "print(df_seeds_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERALL STATISTICS (across all targets)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "mean_pct_sig = df_seeds_summary['Pct_significant'].mean()\n",
    "std_pct_sig = df_seeds_summary['Pct_significant'].std()\n",
    "mean_r_delta_all = df_seeds_summary['Mean_r_delta'].mean()\n",
    "\n",
    "print(f\"Mean % significant seeds: {mean_pct_sig:.1f}% ± {std_pct_sig:.1f}%\")\n",
    "print(f\"Mean delta-FC correlation: {mean_r_delta_all:.4f}\")\n",
    "print(f\"\\n→ On average, {mean_pct_sig:.0f}% of seeds show SIGNIFICANT seed-FC correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760a6d5",
   "metadata": {},
   "source": [
    "---\n",
    "# Part III: Full FC Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2686df",
   "metadata": {},
   "source": [
    "Compare entire FC and delta-FC matrices between empirical and simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adecfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART III: FULL FC MATRIX VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nCompare entire FC and ΔFC matrices (empirical vs simulated)\\n\")\n",
    "\n",
    "fc_matrix_results = {\n",
    "    'rest_fc': [],\n",
    "    'stim_fc': [],\n",
    "    'delta_fc': []\n",
    "}\n",
    "\n",
    "for sub_id in sorted(dataset_emp.keys()):\n",
    "    if sub_id not in dataset_sim:\n",
    "        continue\n",
    "    \n",
    "    # --- REST FC ---\n",
    "    rest_emp_list = []\n",
    "    rest_sim_list = []\n",
    "    \n",
    "    for run in dataset_emp[sub_id].get(\"task-rest\", {}).values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            rest_emp_list.append(ts)\n",
    "    \n",
    "    for run in dataset_sim[sub_id].get(\"task-rest\", {}).values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            rest_sim_list.append(ts)\n",
    "    \n",
    "    if not rest_emp_list or not rest_sim_list:\n",
    "        continue\n",
    "    \n",
    "    rest_emp = np.concatenate(rest_emp_list, axis=0)\n",
    "    rest_sim = np.concatenate(rest_sim_list, axis=0)\n",
    "    \n",
    "    fc_rest_emp = compute_fc_matrix(rest_emp)\n",
    "    fc_rest_sim = compute_fc_matrix(rest_sim)\n",
    "    \n",
    "    vec_rest_emp = upper_triangle_vec(fc_rest_emp, k=1)\n",
    "    vec_rest_sim = upper_triangle_vec(fc_rest_sim, k=1)\n",
    "    r_rest_fc = pearsonr(vec_rest_emp, vec_rest_sim)[0]\n",
    "    fc_matrix_results['rest_fc'].append(r_rest_fc)\n",
    "    \n",
    "    # --- STIM and DELTA FC ---\n",
    "    stim_runs_emp = dataset_emp[sub_id].get(\"task-stim\", {})\n",
    "    stim_runs_sim = dataset_sim[sub_id].get(\"task-stim\", {})\n",
    "    \n",
    "    if not stim_runs_emp or not stim_runs_sim:\n",
    "        continue\n",
    "    \n",
    "    stim_emp_list = []\n",
    "    stim_sim_list = []\n",
    "    \n",
    "    for run in stim_runs_emp.values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            stim_emp_list.append(ts)\n",
    "    \n",
    "    for run in stim_runs_sim.values():\n",
    "        ts = run.get(\"time series\")\n",
    "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
    "            stim_sim_list.append(ts)\n",
    "    \n",
    "    if stim_emp_list and stim_sim_list:\n",
    "        stim_emp = np.concatenate(stim_emp_list, axis=0)\n",
    "        stim_sim = np.concatenate(stim_sim_list, axis=0)\n",
    "        \n",
    "        fc_stim_emp = compute_fc_matrix(stim_emp)\n",
    "        fc_stim_sim = compute_fc_matrix(stim_sim)\n",
    "        \n",
    "        vec_stim_emp = upper_triangle_vec(fc_stim_emp, k=1)\n",
    "        vec_stim_sim = upper_triangle_vec(fc_stim_sim, k=1)\n",
    "        r_stim_fc = pearsonr(vec_stim_emp, vec_stim_sim)[0]\n",
    "        fc_matrix_results['stim_fc'].append(r_stim_fc)\n",
    "        \n",
    "        # DELTA FC\n",
    "        delta_fc_emp = fc_stim_emp - fc_rest_emp\n",
    "        delta_fc_sim = fc_stim_sim - fc_rest_sim\n",
    "        \n",
    "        vec_delta_emp = upper_triangle_vec(delta_fc_emp, k=1)\n",
    "        vec_delta_sim = upper_triangle_vec(delta_fc_sim, k=1)\n",
    "        r_delta_fc = pearsonr(vec_delta_emp, vec_delta_sim)[0]\n",
    "        fc_matrix_results['delta_fc'].append(r_delta_fc)\n",
    "\n",
    "print(f\"✓ Computed full FC correlations for {len(fc_matrix_results['rest_fc'])} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609db67",
   "metadata": {},
   "source": [
    "### Part III Results: Full FC Matrix Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677786ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FULL FC MATRIX VALIDATION: RESULTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "fc_summary = []\n",
    "\n",
    "for condition in ['rest_fc', 'stim_fc', 'delta_fc']:\n",
    "    data = np.array(fc_matrix_results[condition])\n",
    "    data = data[np.isfinite(data)]\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    \n",
    "    t_stat, t_p = ttest_1samp(data, 0)\n",
    "    \n",
    "    fc_summary.append({\n",
    "        'Condition': condition.replace('_fc', '').upper(),\n",
    "        'N_subjects': len(data),\n",
    "        'Mean_r': data.mean(),\n",
    "        'Std_r': data.std(),\n",
    "        'Min_r': data.min(),\n",
    "        'Max_r': data.max(),\n",
    "        'p_value': t_p,\n",
    "        'Significant': 'YES' if t_p < 0.05 else 'NO',\n",
    "    })\n",
    "\n",
    "df_fc_summary = pd.DataFrame(fc_summary)\n",
    "print(df_fc_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  REST FC correlation: baseline connectivity similarity\")\n",
    "print(\"  STIM FC correlation: connectivity during stimulation\")\n",
    "print(\"  DELTA FC correlation: stimulation-induced FC changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1dc2b2",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a605113",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "## VALIDATION RESULTS\n",
    "\n",
    "### Part I: Target-Seed Validation\n",
    "- Uses only the stimulated target region as seed\n",
    "- Indicates: Does the model capture TMS effects on target connectivity?\n",
    "\"\"\")\n",
    "\n",
    "rest_data = np.array(summary_by_condition['rest'])[np.isfinite(summary_by_condition['rest'])]\n",
    "stim_data = np.array(summary_by_condition['stim'])[np.isfinite(summary_by_condition['stim'])]\n",
    "delta_data = np.array(summary_by_condition['delta'])[np.isfinite(summary_by_condition['delta'])]\n",
    "\n",
    "print(f\"  REST:  mean r = {rest_data.mean():.4f}, p = {ttest_1samp(rest_data, 0)[1]:.6f}\")\n",
    "print(f\"  STIM:  mean r = {stim_data.mean():.4f}, p = {ttest_1samp(stim_data, 0)[1]:.6f}\")\n",
    "print(f\"  DELTA: mean r = {delta_data.mean():.4f}, p = {ttest_1samp(delta_data, 0)[1]:.6f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "### Part II: All-Seeds Validation\n",
    "- Repeats analysis for all 450 possible seeds\n",
    "- Indicates: What % of brain seeds show significant correlation?\n",
    "\"\"\")\n",
    "print(f\"  Average % significant seeds per target: {mean_pct_sig:.1f}% ± {std_pct_sig:.1f}%\")\n",
    "print(f\"  → Interpretation: {mean_pct_sig:.0f}% of seed regions significantly capture\")\n",
    "print(f\"     empirical-vs-simulated correlations\")\n",
    "\n",
    "print(\"\"\"\n",
    "### Part III: Full FC Matrix Validation\n",
    "- Compares entire correlation matrices (not just seeds)\n",
    "- Indicates: Overall FC pattern similarity\n",
    "\"\"\")\n",
    "rest_fc_data = np.array(fc_matrix_results['rest_fc'])[np.isfinite(fc_matrix_results['rest_fc'])]\n",
    "delta_fc_data = np.array(fc_matrix_results['delta_fc'])[np.isfinite(fc_matrix_results['delta_fc'])]\n",
    "\n",
    "if len(rest_fc_data) > 0:\n",
    "    print(f\"  REST FC:  mean r = {rest_fc_data.mean():.4f}, p = {ttest_1samp(rest_fc_data, 0)[1]:.6f}\")\n",
    "if len(delta_fc_data) > 0:\n",
    "    print(f\"  DELTA FC: mean r = {delta_fc_data.mean():.4f}, p = {ttest_1samp(delta_fc_data, 0)[1]:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION: IS SIMULATED TMS RELATED TO EMPIRICAL TMS?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Decision logic\n",
    "delta_sig = ttest_1samp(delta_data, 0)[1] < 0.05 if len(delta_data) > 0 else False\n",
    "delta_fc_sig = ttest_1samp(delta_fc_data, 0)[1] < 0.05 if len(delta_fc_data) > 0 else False\n",
    "pct_seeds_high = mean_pct_sig > 30  # If >30% of seeds are significant\n",
    "\n",
    "print(\"\\nCriteria for validation:\")\n",
    "print(f\"  1. Target-seed DELTA significant (p < 0.05): {'✓ YES' if delta_sig else '✗ NO'}\")\n",
    "print(f\"  2. Full FC DELTA significant (p < 0.05): {'✓ YES' if delta_fc_sig else '✗ NO'}\")\n",
    "print(f\"  3. >30% of seeds significant: {'✓ YES' if pct_seeds_high else '✗ NO'}\")\n",
    "\n",
    "if delta_sig and (delta_fc_sig or pct_seeds_high):\n",
    "    print(\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║ ✓ STRONG VALIDATION: YES, simulated TMS effects ARE related   ║\n",
    "║ to empirical TMS effects                                       ║\n",
    "║                                                                ║\n",
    "║ The model successfully captures TMS-induced connectivity       ║\n",
    "║ changes both at target-seed and distributed network levels.   ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "elif delta_sig:\n",
    "    print(\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║ ⚠ MODERATE VALIDATION: Partial support for model validity     ║\n",
    "║                                                                ║\n",
    "║ Target-seed effects are captured, but full FC patterns show   ║\n",
    "║ limited correlation. The model may capture local effects      ║\n",
    "║ but miss distributed network reorganization.                  ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════╗\n",
    "║ ✗ LIMITED VALIDATION: Simulated effects NOT significantly     ║\n",
    "║ related to empirical effects                                   ║\n",
    "║                                                                ║\n",
    "║ The population model may be insufficient for capturing        ║\n",
    "║ TMS-specific effects. Subject-specific or hierarchical        ║\n",
    "║ models may be needed.                                          ║\n",
    "╚════════════════════════════════════════════════════════════════╝\n",
    "\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df7f08",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "comprehensive_results = {\n",
    "    'metadata': {\n",
    "        'validation_type': 'Comprehensive TMS-fMRI ANN Validation',\n",
    "        'timestamp': str(pd.Timestamp.now()),\n",
    "    },\n",
    "    'part_i_target_seed': {\n",
    "        'rest_mean_r': float(rest_data.mean()),\n",
    "        'rest_p_value': float(ttest_1samp(rest_data, 0)[1]),\n",
    "        'stim_mean_r': float(stim_data.mean()),\n",
    "        'stim_p_value': float(ttest_1samp(stim_data, 0)[1]),\n",
    "        'delta_mean_r': float(delta_data.mean()),\n",
    "        'delta_p_value': float(ttest_1samp(delta_data, 0)[1]),\n",
    "        'n_observations': int(len(delta_data)),\n",
    "    },\n",
    "    'part_ii_all_seeds': {\n",
    "        'mean_pct_significant_seeds': float(mean_pct_sig),\n",
    "        'std_pct_significant_seeds': float(std_pct_sig),\n",
    "        'n_targets': int(len(df_seeds_summary)),\n",
    "        'per_target_summary': df_seeds_summary.to_dict('records'),\n",
    "    },\n",
    "    'part_iii_full_fc': df_fc_summary.to_dict('records'),\n",
    "}\n",
    "\n",
    "with open(VALIDATION_RESULTS_JSON, 'w') as f:\n",
    "    json.dump(comprehensive_results, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved comprehensive validation results to:\")\n",
    "print(f\"  {VALIDATION_RESULTS_JSON}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
