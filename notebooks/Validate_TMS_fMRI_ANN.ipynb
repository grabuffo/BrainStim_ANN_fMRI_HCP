{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Validate_TMS_fMRI_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d289d08",
      "metadata": {
        "id": "8d289d08"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Validate_TMS_fMRI_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c67626",
      "metadata": {
        "id": "b6c67626"
      },
      "source": [
        "# Validate TMS-fMRI Simulations with Population ANN\n",
        "\n",
        "Comprehensive validation of synthetic TMS-fMRI data by comparing empirical vs. simulated connectivity patterns.\n",
        "\n",
        "## Validation Strategy\n",
        "\n",
        "### i) **Target-Seed Validation** (per target region)\n",
        "For each stimulated target region, compute seed-based FC (rest, stim, delta) correlations between empirical and simulated data.\n",
        "\n",
        "### ii) **All-Seeds Validation** (per target region, repeated for all 450 seeds)\n",
        "For each target region and each possible seed (450 ROIs), compute seed-FC correlations. Summarize:\n",
        "- Mean correlation for each seed\n",
        "- Statistical significance (p-value) for each seed\n",
        "- **Percentage of significant seeds** (how many seeds have r significantly > 0?)\n",
        "\n",
        "### iii) **Full FC Validation** (entire correlation matrices)\n",
        "Compare entire static FC and delta-FC matrices between empirical and simulated across all conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff9c584",
      "metadata": {
        "id": "dff9c584"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0f297787",
      "metadata": {
        "id": "0f297787",
        "outputId": "dc5f5da6-d7a0-4551-8bbe-0ea5ae960900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Imports successful\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, sys, pickle, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, ttest_1samp\n",
        "\n",
        "print(\"✓ Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c4e9a2",
      "metadata": {
        "id": "45c4e9a2"
      },
      "source": [
        "## Define Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "db9edb41",
      "metadata": {
        "id": "db9edb41",
        "outputId": "0ab313c4-902a-49a1-aa4a-6849d9392258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Empirical dataset: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/TMS_fMRI/dataset_tian50_schaefer400_allruns.pkl\n",
            "✓ Simulated dataset: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/ANN_vs_tms_fmri/dataset_simulated_populationANN.pkl\n",
            "✓ Output: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/ANN_vs_tms_fmri/validation_results_comprehensive.json\n"
          ]
        }
      ],
      "source": [
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
        "\n",
        "DATASET_EMP_PKL = os.path.join(BASE, \"TMS_fMRI\", \"dataset_tian50_schaefer400_allruns.pkl\")\n",
        "PREPROC_ROOT = os.path.join(BASE, \"preprocessed_subjects_tms_fmri\")\n",
        "OUT_DIR = os.path.join(PREPROC_ROOT, \"ANN_vs_tms_fmri\")\n",
        "\n",
        "DATASET_SIM_PKL = os.path.join(OUT_DIR, \"dataset_simulated_populationANN.pkl\")\n",
        "VALIDATION_RESULTS_JSON = os.path.join(OUT_DIR, \"validation_results_comprehensive.json\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"✓ Empirical dataset: {DATASET_EMP_PKL}\")\n",
        "print(f\"✓ Simulated dataset: {DATASET_SIM_PKL}\")\n",
        "print(f\"✓ Output: {VALIDATION_RESULTS_JSON}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44eeee37",
      "metadata": {
        "id": "44eeee37"
      },
      "source": [
        "## Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "787b73d8",
      "metadata": {
        "id": "787b73d8",
        "outputId": "45d9fcf9-724c-4a81-dbf7-200409e89256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading empirical dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4048342287.py:3: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  dataset_emp = pickle.load(f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded 46 subjects (empirical)\n",
            "\n",
            "Loading simulated dataset...\n",
            "✓ Loaded 46 subjects (simulated)\n",
            "\n",
            "✓ Subjects match across datasets\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading empirical dataset...\")\n",
        "with open(DATASET_EMP_PKL, \"rb\") as f:\n",
        "    dataset_emp = pickle.load(f)\n",
        "print(f\"✓ Loaded {len(dataset_emp)} subjects (empirical)\")\n",
        "\n",
        "print(\"\\nLoading simulated dataset...\")\n",
        "with open(DATASET_SIM_PKL, \"rb\") as f:\n",
        "    dataset_sim = pickle.load(f)\n",
        "print(f\"✓ Loaded {len(dataset_sim)} subjects (simulated)\")\n",
        "\n",
        "# Sanity check\n",
        "assert set(dataset_emp.keys()) == set(dataset_sim.keys()), \"Subject mismatch!\"\n",
        "print(f\"\\n✓ Subjects match across datasets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8ddc3e",
      "metadata": {
        "id": "8d8ddc3e"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b70a30c6",
      "metadata": {
        "id": "b70a30c6",
        "outputId": "5b7033b5-d1ac-4ff6-9a73-467504d241c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Helper functions defined (cortical-only mode)\n"
          ]
        }
      ],
      "source": [
        "def safe_target_idx(target_vec):\n",
        "    \"\"\"Extract target region index from one-hot vector.\"\"\"\n",
        "    if target_vec is None:\n",
        "        return None\n",
        "    v = np.asarray(target_vec).astype(int).ravel()\n",
        "    if v.size == 0 or v.sum() != 1:\n",
        "        return None\n",
        "    return int(np.argmax(v))\n",
        "\n",
        "def seed_based_fc(ts, seed_idx, cortical_only=True):\n",
        "    \"\"\"Compute seed-based FC: correlation of seed with all other regions.\n",
        "\n",
        "    Args:\n",
        "        ts: (T, N) time series (N=450 for full, or 400 if pre-extracted cortical)\n",
        "        seed_idx: index of seed region (0-399 for cortical, 0-449 for full)\n",
        "        cortical_only: if True, extract cortical regions (50-449) and adjust indices\n",
        "\n",
        "    Returns:\n",
        "        fc_seed: correlation vector with all regions\n",
        "    \"\"\"\n",
        "    if cortical_only:\n",
        "        ts = ts[:, 50:]  # Keep only cortical (Schaefer 400)\n",
        "        seed_idx = seed_idx - 50  # Adjust seed index (0-399)\n",
        "\n",
        "    if seed_idx < 0 or seed_idx >= ts.shape[1]:\n",
        "        return None\n",
        "\n",
        "    seed_ts = ts[:, seed_idx]  # (T,)\n",
        "    # Correlate seed with all regions\n",
        "    corrmat = np.corrcoef(seed_ts, ts.T)  # (1+N, 1+N)\n",
        "    fc_seed = corrmat[0, 1:]  # (N,) - correlations with all regions\n",
        "    return fc_seed\n",
        "\n",
        "def compute_fc_matrix(ts, cortical_only=True):\n",
        "    \"\"\"Compute full FC matrix from time series.\"\"\"\n",
        "    if cortical_only:\n",
        "        ts = ts[:, 50:]  # Keep only cortical\n",
        "    return np.corrcoef(ts.T).astype(np.float32)\n",
        "\n",
        "def upper_triangle_vec(mat, k=1):\n",
        "    \"\"\"Extract upper triangle as 1D vector.\"\"\"\n",
        "    iu = np.triu_indices(mat.shape[0], k=k)\n",
        "    return mat[iu]\n",
        "\n",
        "print(\"✓ Helper functions defined (cortical-only mode)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3dfc19b",
      "metadata": {
        "id": "e3dfc19b"
      },
      "source": [
        "---\n",
        "# Part I: Target-Seed Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c403c9e8",
      "metadata": {
        "id": "c403c9e8"
      },
      "source": [
        "For each target region, validate using only that region as the seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "935ba591",
      "metadata": {
        "id": "935ba591",
        "outputId": "c7937064-bf0a-4131-fcca-12d4658b99f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PART I: TARGET-SEED VALIDATION (CORTICAL REGIONS ONLY)\n",
            "======================================================================\n",
            "\n",
            "For each target region, compute seed-FC correlations (empirical vs simulated)\n",
            "Conditions: REST, STIM, DELTA (stim - rest)\n",
            "Using only cortical regions (Schaefer 400, indices 50-449)\n",
            "\n",
            "\n",
            "✓ Computed target-seed correlations for 11 target regions (cortical only)\n",
            "\n",
            "Per-target summary (first 5 targets):\n",
            "  target_155: 42 observations\n",
            "  target_220: 28 observations\n",
            "  target_231: 44 observations\n",
            "  target_305: 43 observations\n",
            "  target_342: 41 observations\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"PART I: TARGET-SEED VALIDATION (CORTICAL REGIONS ONLY)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nFor each target region, compute seed-FC correlations (empirical vs simulated)\")\n",
        "print(\"Conditions: REST, STIM, DELTA (stim - rest)\")\n",
        "print(\"Using only cortical regions (Schaefer 400, indices 50-449)\\n\")\n",
        "\n",
        "# Organize results by target\n",
        "target_seed_results = {}\n",
        "\n",
        "for sub_id in sorted(dataset_emp.keys()):\n",
        "    if sub_id not in dataset_sim:\n",
        "        continue\n",
        "\n",
        "    sub_emp = dataset_emp[sub_id]\n",
        "    sub_sim = dataset_sim[sub_id]\n",
        "\n",
        "    # --- REST condition (baseline) ---\n",
        "    rest_emp_list = []\n",
        "    rest_sim_list = []\n",
        "\n",
        "    for run in sub_emp.get(\"task-rest\", {}).values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            rest_emp_list.append(ts)\n",
        "\n",
        "    for run in sub_sim.get(\"task-rest\", {}).values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            rest_sim_list.append(ts)\n",
        "\n",
        "    if not rest_emp_list or not rest_sim_list:\n",
        "        continue\n",
        "\n",
        "    # Average across rest runs\n",
        "    rest_emp = np.concatenate(rest_emp_list, axis=0)\n",
        "    rest_sim = np.concatenate(rest_sim_list, axis=0)\n",
        "\n",
        "    # Compute rest FC (cortical only)\n",
        "    fc_rest_emp = compute_fc_matrix(rest_emp, cortical_only=True)\n",
        "    fc_rest_sim = compute_fc_matrix(rest_sim, cortical_only=True)\n",
        "\n",
        "    # --- STIM condition ---\n",
        "    stim_runs_emp = sub_emp.get(\"task-stim\", {})\n",
        "    stim_runs_sim = sub_sim.get(\"task-stim\", {})\n",
        "\n",
        "    if not stim_runs_emp or not stim_runs_sim:\n",
        "        continue\n",
        "\n",
        "    # Process each stim run\n",
        "    for run_idx, run_emp in stim_runs_emp.items():\n",
        "        run_sim = stim_runs_sim.get(run_idx)\n",
        "        if run_sim is None:\n",
        "            continue\n",
        "\n",
        "        ts_emp = run_emp.get(\"time series\")\n",
        "        ts_sim = run_sim.get(\"time series\")\n",
        "        target_vec = run_emp.get(\"target\")\n",
        "\n",
        "        if not isinstance(ts_emp, np.ndarray) or not isinstance(ts_sim, np.ndarray):\n",
        "            continue\n",
        "        if ts_emp.shape[1] < 450 or ts_sim.shape[1] < 450:\n",
        "            continue\n",
        "\n",
        "        target_idx = safe_target_idx(target_vec)\n",
        "        if target_idx is None:\n",
        "            continue\n",
        "\n",
        "        # Skip if target is not in cortical range (50-449)\n",
        "        if target_idx < 50 or target_idx >= 450:\n",
        "            continue\n",
        "\n",
        "        target_key = f\"target_{target_idx:03d}\"\n",
        "\n",
        "        if target_key not in target_seed_results:\n",
        "            target_seed_results[target_key] = {\n",
        "                'target_idx': target_idx,\n",
        "                'correlations': []\n",
        "            }\n",
        "\n",
        "        # Compute seed-based FC using target as seed (cortical only)\n",
        "        fc_seed_rest_emp = seed_based_fc(rest_emp, target_idx, cortical_only=True)\n",
        "        fc_seed_rest_sim = seed_based_fc(rest_sim, target_idx, cortical_only=True)\n",
        "\n",
        "        fc_seed_stim_emp = seed_based_fc(ts_emp, target_idx, cortical_only=True)\n",
        "        fc_seed_stim_sim = seed_based_fc(ts_sim, target_idx, cortical_only=True)\n",
        "\n",
        "        if fc_seed_rest_emp is None or fc_seed_stim_emp is None:\n",
        "            continue\n",
        "\n",
        "        # Correlate seed-FC vectors\n",
        "        r_rest = np.corrcoef(fc_seed_rest_emp, fc_seed_rest_sim)[0, 1]\n",
        "        r_stim = np.corrcoef(fc_seed_stim_emp, fc_seed_stim_sim)[0, 1]\n",
        "\n",
        "        # Delta: stimulation-induced change\n",
        "        delta_emp = fc_seed_stim_emp - fc_seed_rest_emp\n",
        "        delta_sim = fc_seed_stim_sim - fc_seed_rest_sim\n",
        "        r_delta = np.corrcoef(delta_emp, delta_sim)[0, 1]\n",
        "\n",
        "        target_seed_results[target_key]['correlations'].append({\n",
        "            'subject': sub_id,\n",
        "            'r_rest': float(r_rest),\n",
        "            'r_stim': float(r_stim),\n",
        "            'r_delta': float(r_delta),\n",
        "        })\n",
        "\n",
        "print(f\"\\n✓ Computed target-seed correlations for {len(target_seed_results)} target regions (cortical only)\")\n",
        "print(f\"\\nPer-target summary (first 5 targets):\")\n",
        "for target_key in sorted(target_seed_results.keys())[:5]:\n",
        "    n_corrs = len(target_seed_results[target_key]['correlations'])\n",
        "    print(f\"  {target_key}: {n_corrs} observations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e95cf918",
      "metadata": {
        "id": "e95cf918"
      },
      "source": [
        "### Part I Results: Target-Seed Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "32dba680",
      "metadata": {
        "id": "32dba680",
        "outputId": "a438a661-7051-488c-a195-452f7cfde582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TARGET-SEED VALIDATION: SUMMARY\n",
            "======================================================================\n",
            "\n",
            "    Target  N  Mean_r_rest  Mean_r_stim  Mean_r_delta  Std_r_delta\n",
            "target_155 42     0.392334     0.220330     -0.038910     0.116254\n",
            "target_220 28     0.277938     0.175185     -0.008318     0.105876\n",
            "target_231 44     0.491529     0.320990     -0.053627     0.119809\n",
            "target_305 43     0.455445     0.355081     -0.032305     0.133081\n",
            "target_342 41     0.569204     0.316064     -0.053505     0.118253\n",
            "target_359 43     0.479142     0.283885     -0.015950     0.110008\n",
            "target_366 37     0.538778     0.393329     -0.080275     0.138712\n",
            "target_386 30     0.480694     0.287261     -0.025812     0.137367\n",
            "target_392 35     0.333635     0.220460     -0.060973     0.122201\n",
            "target_401 45     0.426069     0.286341     -0.050544     0.111824\n",
            "target_403 44     0.393633     0.346979     -0.056354     0.128175\n",
            "\n",
            "======================================================================\n",
            "POOLED ACROSS ALL TARGETS\n",
            "======================================================================\n",
            "\n",
            "\n",
            "REST condition:\n",
            "  N observations: 432\n",
            "  Mean r: 0.4443 ± 0.1555\n",
            "  Range: [-0.0515, 0.7295]\n",
            "  t-test p-value: 0.000000\n",
            "  Significant? YES\n",
            "\n",
            "STIM condition:\n",
            "  N observations: 432\n",
            "  Mean r: 0.2957 ± 0.1383\n",
            "  Range: [-0.1042, 0.6587]\n",
            "  t-test p-value: 0.000000\n",
            "  Significant? YES\n",
            "\n",
            "DELTA condition:\n",
            "  N observations: 432\n",
            "  Mean r: -0.0443 ± 0.1238\n",
            "  Range: [-0.4622, 0.2695]\n",
            "  t-test p-value: 0.000000\n",
            "  Significant? YES\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TARGET-SEED VALIDATION: SUMMARY\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "summary_by_condition = {\n",
        "    'rest': [],\n",
        "    'stim': [],\n",
        "    'delta': []\n",
        "}\n",
        "\n",
        "target_summary_table = []\n",
        "\n",
        "for target_key in sorted(target_seed_results.keys()):\n",
        "    corrs = target_seed_results[target_key]['correlations']\n",
        "\n",
        "    r_rest_vals = np.array([c['r_rest'] for c in corrs if np.isfinite(c['r_rest'])])\n",
        "    r_stim_vals = np.array([c['r_stim'] for c in corrs if np.isfinite(c['r_stim'])])\n",
        "    r_delta_vals = np.array([c['r_delta'] for c in corrs if np.isfinite(c['r_delta'])])\n",
        "\n",
        "    summary_by_condition['rest'].extend(r_rest_vals)\n",
        "    summary_by_condition['stim'].extend(r_stim_vals)\n",
        "    summary_by_condition['delta'].extend(r_delta_vals)\n",
        "\n",
        "    target_summary_table.append({\n",
        "        'Target': target_key,\n",
        "        'N': len(corrs),\n",
        "        'Mean_r_rest': r_rest_vals.mean() if len(r_rest_vals) > 0 else np.nan,\n",
        "        'Mean_r_stim': r_stim_vals.mean() if len(r_stim_vals) > 0 else np.nan,\n",
        "        'Mean_r_delta': r_delta_vals.mean() if len(r_delta_vals) > 0 else np.nan,\n",
        "        'Std_r_delta': r_delta_vals.std() if len(r_delta_vals) > 0 else np.nan,\n",
        "    })\n",
        "\n",
        "df_targets = pd.DataFrame(target_summary_table)\n",
        "print(df_targets.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"POOLED ACROSS ALL TARGETS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for condition in ['rest', 'stim', 'delta']:\n",
        "    data = np.array(summary_by_condition[condition])\n",
        "    data = data[np.isfinite(data)]\n",
        "    t_stat, t_p = ttest_1samp(data, 0) if len(data) > 0 else (np.nan, np.nan)\n",
        "\n",
        "    print(f\"\\n{condition.upper()} condition:\")\n",
        "    print(f\"  N observations: {len(data)}\")\n",
        "    print(f\"  Mean r: {data.mean():.4f} ± {data.std():.4f}\")\n",
        "    print(f\"  Range: [{data.min():.4f}, {data.max():.4f}]\")\n",
        "    print(f\"  t-test p-value: {t_p:.6f}\")\n",
        "    print(f\"  Significant? {'YES' if t_p < 0.05 else 'NO'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cf5e39d",
      "metadata": {
        "id": "2cf5e39d"
      },
      "source": [
        "---\n",
        "# Part II: All-Seeds Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "710444da",
      "metadata": {
        "id": "710444da"
      },
      "source": [
        "For each target region, repeat the analysis using ALL 450 regions as seeds. Calculate:\n",
        "- Correlation for each seed\n",
        "- Significance (p-value) for each seed\n",
        "- **% of seeds with significant correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "da3ee8ed",
      "metadata": {
        "id": "da3ee8ed",
        "outputId": "19e07b8e-503c-4209-82ed-50da8dbc606c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PART II: ALL-SEEDS VALIDATION (PER TARGET REGION)\n",
            "======================================================================\n",
            "\n",
            "For each target region, compute seed-FC for all 450 seeds.\n",
            "Calculate significance and % significant seeds.\n",
            "\n",
            "Computing global rest FC matrices...\n",
            "  Empirical rest: (11760, 450)\n",
            "  Simulated rest: (11760, 450)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4203029691.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mfc_seed_rest_emp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_based_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest_emp_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_regions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mfc_seed_rest_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_based_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest_sim_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_regions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mfc_seed_stim_emp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_based_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_emp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_regions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2161241700.py\u001b[0m in \u001b[0;36mseed_based_fc\u001b[0;34m(ts, seed_idx, all_regions)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mseed_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_idx\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (T,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Correlate seed with all regions (including itself initially)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mcorrmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1+N, 1+N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mfc_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (N,) - correlations with all regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfc_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2912\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[1;32m   2913\u001b[0m                       DeprecationWarning, stacklevel=2)\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2770\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2771\u001b[0m         \u001b[0mX_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2772\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2773\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART II: ALL-SEEDS VALIDATION (CORTICAL REGIONS ONLY)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nFor each target region, compute seed-FC for all 400 CORTICAL seeds.\")\n",
        "print(\"Calculate significance and % significant seeds.\\n\")\n",
        "\n",
        "all_seeds_results = {}\n",
        "\n",
        "# Compute global rest FC (across all subjects/runs) - cortical only\n",
        "print(\"Computing global rest FC matrices (cortical only)...\")\n",
        "rest_emp_all = []\n",
        "rest_sim_all = []\n",
        "\n",
        "for sub_id in sorted(dataset_emp.keys()):\n",
        "    for run in dataset_emp[sub_id].get(\"task-rest\", {}).values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            rest_emp_all.append(ts)\n",
        "\n",
        "    for run in dataset_sim[sub_id].get(\"task-rest\", {}).values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            rest_sim_all.append(ts)\n",
        "\n",
        "rest_emp_concat = np.concatenate(rest_emp_all, axis=0)\n",
        "rest_sim_concat = np.concatenate(rest_sim_all, axis=0)\n",
        "print(f\"  Empirical rest: {rest_emp_concat.shape}\")\n",
        "print(f\"  Simulated rest: {rest_sim_concat.shape}\")\n",
        "\n",
        "# --- Now iterate over targets ---\n",
        "for sub_id in sorted(dataset_emp.keys()):\n",
        "    if sub_id not in dataset_sim:\n",
        "        continue\n",
        "\n",
        "    stim_runs_emp = dataset_emp[sub_id].get(\"task-stim\", {})\n",
        "    stim_runs_sim = dataset_sim[sub_id].get(\"task-stim\", {})\n",
        "\n",
        "    for run_idx, run_emp in stim_runs_emp.items():\n",
        "        run_sim = stim_runs_sim.get(run_idx)\n",
        "        if run_sim is None:\n",
        "            continue\n",
        "\n",
        "        ts_emp = run_emp.get(\"time series\")\n",
        "        ts_sim = run_sim.get(\"time series\")\n",
        "        target_vec = run_emp.get(\"target\")\n",
        "\n",
        "        if not isinstance(ts_emp, np.ndarray) or not isinstance(ts_sim, np.ndarray):\n",
        "            continue\n",
        "        if ts_emp.shape[1] < 450 or ts_sim.shape[1] < 450:\n",
        "            continue\n",
        "\n",
        "        target_idx = safe_target_idx(target_vec)\n",
        "        if target_idx is None:\n",
        "            continue\n",
        "\n",
        "        # Skip if target is not cortical\n",
        "        if target_idx < 50 or target_idx >= 450:\n",
        "            continue\n",
        "\n",
        "        target_key = f\"target_{target_idx:03d}\"\n",
        "\n",
        "        if target_key not in all_seeds_results:\n",
        "            all_seeds_results[target_key] = {\n",
        "                'target_idx': target_idx,\n",
        "                'seed_results': {}\n",
        "            }\n",
        "\n",
        "        # For each of 400 CORTICAL seeds (indices 50-449)\n",
        "        for seed_idx in range(50, 450):\n",
        "            fc_seed_rest_emp = seed_based_fc(rest_emp_concat, seed_idx, cortical_only=True)\n",
        "            fc_seed_rest_sim = seed_based_fc(rest_sim_concat, seed_idx, cortical_only=True)\n",
        "\n",
        "            fc_seed_stim_emp = seed_based_fc(ts_emp, seed_idx, cortical_only=True)\n",
        "            fc_seed_stim_sim = seed_based_fc(ts_sim, seed_idx, cortical_only=True)\n",
        "\n",
        "            if fc_seed_rest_emp is None or fc_seed_stim_emp is None:\n",
        "                continue\n",
        "\n",
        "            # REST correlation\n",
        "            r_rest = np.corrcoef(fc_seed_rest_emp, fc_seed_rest_sim)[0, 1]\n",
        "\n",
        "            # STIM correlation\n",
        "            r_stim = np.corrcoef(fc_seed_stim_emp, fc_seed_stim_sim)[0, 1]\n",
        "\n",
        "            # DELTA correlation\n",
        "            delta_emp = fc_seed_stim_emp - fc_seed_rest_emp\n",
        "            delta_sim = fc_seed_stim_sim - fc_seed_rest_sim\n",
        "            r_delta = np.corrcoef(delta_emp, delta_sim)[0, 1]\n",
        "\n",
        "            seed_key = f\"seed_{seed_idx:03d}\"\n",
        "            if seed_key not in all_seeds_results[target_key]['seed_results']:\n",
        "                all_seeds_results[target_key]['seed_results'][seed_key] = []\n",
        "\n",
        "            all_seeds_results[target_key]['seed_results'][seed_key].append({\n",
        "                'subject': sub_id,\n",
        "                'r_rest': float(r_rest),\n",
        "                'r_stim': float(r_stim),\n",
        "                'r_delta': float(r_delta),\n",
        "            })\n",
        "\n",
        "print(f\"\\n✓ Computed all-seeds correlations for {len(all_seeds_results)} target regions (400 cortical seeds each)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e78686b",
      "metadata": {
        "id": "0e78686b"
      },
      "source": [
        "### Part II Results: Per-Target Statistics with % Significant Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e412dc58",
      "metadata": {
        "id": "e412dc58"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL-SEEDS VALIDATION: RESULTS PER TARGET REGION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "target_seeds_summary = []\n",
        "\n",
        "for target_key in sorted(all_seeds_results.keys()):\n",
        "    target_data = all_seeds_results[target_key]\n",
        "    seed_results_dict = target_data['seed_results']\n",
        "\n",
        "    all_r_delta = []\n",
        "    significant_count = 0\n",
        "    total_seeds = 0\n",
        "\n",
        "    for seed_key in sorted(seed_results_dict.keys()):\n",
        "        seed_corrs = seed_results_dict[seed_key]\n",
        "\n",
        "        # Pool correlations across subjects/runs for this seed\n",
        "        r_delta_vals = np.array([c['r_delta'] for c in seed_corrs if np.isfinite(c['r_delta'])])\n",
        "\n",
        "        if len(r_delta_vals) == 0:\n",
        "            continue\n",
        "\n",
        "        all_r_delta.extend(r_delta_vals)\n",
        "        total_seeds += 1\n",
        "\n",
        "        # Test if mean r_delta significantly > 0\n",
        "        t_stat, p_val = ttest_1samp(r_delta_vals, 0)\n",
        "        if p_val < 0.05:\n",
        "            significant_count += 1\n",
        "\n",
        "    pct_significant = (significant_count / total_seeds * 100) if total_seeds > 0 else 0\n",
        "    all_r_delta = np.array(all_r_delta)\n",
        "\n",
        "    target_seeds_summary.append({\n",
        "        'Target': target_key,\n",
        "        'N_seeds': total_seeds,\n",
        "        'Mean_r_delta': all_r_delta.mean() if len(all_r_delta) > 0 else np.nan,\n",
        "        'Std_r_delta': all_r_delta.std() if len(all_r_delta) > 0 else np.nan,\n",
        "        'Sig_seeds_count': significant_count,\n",
        "        'Pct_significant': pct_significant,\n",
        "    })\n",
        "\n",
        "df_seeds_summary = pd.DataFrame(target_seeds_summary)\n",
        "print(df_seeds_summary.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL STATISTICS (across all targets)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "mean_pct_sig = df_seeds_summary['Pct_significant'].mean()\n",
        "std_pct_sig = df_seeds_summary['Pct_significant'].std()\n",
        "mean_r_delta_all = df_seeds_summary['Mean_r_delta'].mean()\n",
        "\n",
        "print(f\"Mean % significant seeds: {mean_pct_sig:.1f}% ± {std_pct_sig:.1f}%\")\n",
        "print(f\"Mean delta-FC correlation: {mean_r_delta_all:.4f}\")\n",
        "print(f\"\\n→ On average, {mean_pct_sig:.0f}% of seeds show SIGNIFICANT seed-FC correlation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b760a6d5",
      "metadata": {
        "id": "b760a6d5"
      },
      "source": [
        "---\n",
        "# Part III: Full FC Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2686df",
      "metadata": {
        "id": "ea2686df"
      },
      "source": [
        "Compare entire FC and delta-FC matrices between empirical and simulated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0adecfde",
      "metadata": {
        "id": "0adecfde",
        "outputId": "aa8fb93a-339e-4b52-a119-444aff649458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PART III: FULL FC MATRIX VALIDATION (CORTICAL REGIONS ONLY)\n",
            "======================================================================\n",
            "\n",
            "Compare entire cortical FC and ΔFC matrices (empirical vs simulated)\n",
            "\n",
            "✓ Computed full cortical FC correlations for 46 subjects\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PART III: FULL FC MATRIX VALIDATION (CORTICAL REGIONS ONLY)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nCompare entire cortical FC and ΔFC matrices (empirical vs simulated)\\n\")\n",
        "\n",
        "fc_matrix_results = {\n",
        "    'rest_fc': [],\n",
        "    'stim_fc': [],\n",
        "    'delta_fc': []\n",
        "}\n",
        "\n",
        "for sub_id in sorted(dataset_emp.keys()):\n",
        "    if sub_id not in dataset_sim:\n",
        "        continue\n",
        "\n",
        "    # --- REST FC ---\n",
        "    rest_emp_list = []\n",
        "    rest_sim_list = []\n",
        "\n",
        "    for run in dataset_emp[sub_id].get(\"task-rest\", {}).values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            rest_emp_list.append(ts)\n",
        "\n",
        "    for run in dataset_sim[sub_id].get(\"task-rest\", {}).values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            rest_sim_list.append(ts)\n",
        "\n",
        "    if not rest_emp_list or not rest_sim_list:\n",
        "        continue\n",
        "\n",
        "    rest_emp = np.concatenate(rest_emp_list, axis=0)\n",
        "    rest_sim = np.concatenate(rest_sim_list, axis=0)\n",
        "\n",
        "    fc_rest_emp = compute_fc_matrix(rest_emp, cortical_only=True)\n",
        "    fc_rest_sim = compute_fc_matrix(rest_sim, cortical_only=True)\n",
        "\n",
        "    vec_rest_emp = upper_triangle_vec(fc_rest_emp, k=1)\n",
        "    vec_rest_sim = upper_triangle_vec(fc_rest_sim, k=1)\n",
        "    r_rest_fc = pearsonr(vec_rest_emp, vec_rest_sim)[0]\n",
        "    fc_matrix_results['rest_fc'].append(r_rest_fc)\n",
        "\n",
        "    # --- STIM and DELTA FC ---\n",
        "    stim_runs_emp = dataset_emp[sub_id].get(\"task-stim\", {})\n",
        "    stim_runs_sim = dataset_sim[sub_id].get(\"task-stim\", {})\n",
        "\n",
        "    if not stim_runs_emp or not stim_runs_sim:\n",
        "        continue\n",
        "\n",
        "    stim_emp_list = []\n",
        "    stim_sim_list = []\n",
        "\n",
        "    for run in stim_runs_emp.values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            stim_emp_list.append(ts)\n",
        "\n",
        "    for run in stim_runs_sim.values():\n",
        "        ts = run.get(\"time series\")\n",
        "        if isinstance(ts, np.ndarray) and ts.shape[1] >= 450:\n",
        "            stim_sim_list.append(ts)\n",
        "\n",
        "    if stim_emp_list and stim_sim_list:\n",
        "        stim_emp = np.concatenate(stim_emp_list, axis=0)\n",
        "        stim_sim = np.concatenate(stim_sim_list, axis=0)\n",
        "\n",
        "        fc_stim_emp = compute_fc_matrix(stim_emp, cortical_only=True)\n",
        "        fc_stim_sim = compute_fc_matrix(stim_sim, cortical_only=True)\n",
        "\n",
        "        vec_stim_emp = upper_triangle_vec(fc_stim_emp, k=1)\n",
        "        vec_stim_sim = upper_triangle_vec(fc_stim_sim, k=1)\n",
        "        r_stim_fc = pearsonr(vec_stim_emp, vec_stim_sim)[0]\n",
        "        fc_matrix_results['stim_fc'].append(r_stim_fc)\n",
        "\n",
        "        # DELTA FC\n",
        "        delta_fc_emp = fc_stim_emp - fc_rest_emp\n",
        "        delta_fc_sim = fc_stim_sim - fc_rest_sim\n",
        "\n",
        "        vec_delta_emp = upper_triangle_vec(delta_fc_emp, k=1)\n",
        "        vec_delta_sim = upper_triangle_vec(delta_fc_sim, k=1)\n",
        "        r_delta_fc = pearsonr(vec_delta_emp, vec_delta_sim)[0]\n",
        "        fc_matrix_results['delta_fc'].append(r_delta_fc)\n",
        "\n",
        "print(f\"✓ Computed full cortical FC correlations for {len(fc_matrix_results['rest_fc'])} subjects\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d609db67",
      "metadata": {
        "id": "d609db67"
      },
      "source": [
        "### Part III Results: Full FC Matrix Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "677786ab",
      "metadata": {
        "id": "677786ab",
        "outputId": "3576ca2c-4058-4504-ed6b-fb9b50e4932f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FULL FC MATRIX VALIDATION: RESULTS\n",
            "======================================================================\n",
            "\n",
            "Condition  N_subjects    Mean_r    Std_r     Min_r    Max_r      p_value Significant\n",
            "     REST          46  0.413785 0.072441  0.165282 0.510039 5.353598e-36         YES\n",
            "     STIM          46  0.435948 0.113153  0.102471 0.574406 1.229821e-28         YES\n",
            "    DELTA          46 -0.021129 0.056595 -0.215577 0.074985 1.595833e-02         YES\n",
            "\n",
            "Interpretation:\n",
            "  REST FC correlation: baseline connectivity similarity\n",
            "  STIM FC correlation: connectivity during stimulation\n",
            "  DELTA FC correlation: stimulation-induced FC changes\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FULL FC MATRIX VALIDATION: RESULTS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "fc_summary = []\n",
        "\n",
        "for condition in ['rest_fc', 'stim_fc', 'delta_fc']:\n",
        "    data = np.array(fc_matrix_results[condition])\n",
        "    data = data[np.isfinite(data)]\n",
        "\n",
        "    if len(data) == 0:\n",
        "        continue\n",
        "\n",
        "    t_stat, t_p = ttest_1samp(data, 0)\n",
        "\n",
        "    fc_summary.append({\n",
        "        'Condition': condition.replace('_fc', '').upper(),\n",
        "        'N_subjects': len(data),\n",
        "        'Mean_r': data.mean(),\n",
        "        'Std_r': data.std(),\n",
        "        'Min_r': data.min(),\n",
        "        'Max_r': data.max(),\n",
        "        'p_value': t_p,\n",
        "        'Significant': 'YES' if t_p < 0.05 else 'NO',\n",
        "    })\n",
        "\n",
        "df_fc_summary = pd.DataFrame(fc_summary)\n",
        "print(df_fc_summary.to_string(index=False))\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"  REST FC correlation: baseline connectivity similarity\")\n",
        "print(\"  STIM FC correlation: connectivity during stimulation\")\n",
        "print(\"  DELTA FC correlation: stimulation-induced FC changes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1dc2b2",
      "metadata": {
        "id": "1f1dc2b2"
      },
      "source": [
        "---\n",
        "# Final Summary & Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a605113",
      "metadata": {
        "id": "6a605113"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPREHENSIVE VALIDATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "## VALIDATION RESULTS\n",
        "\n",
        "### Part I: Target-Seed Validation\n",
        "- Uses only the stimulated target region as seed\n",
        "- Indicates: Does the model capture TMS effects on target connectivity?\n",
        "\"\"\")\n",
        "\n",
        "rest_data = np.array(summary_by_condition['rest'])[np.isfinite(summary_by_condition['rest'])]\n",
        "stim_data = np.array(summary_by_condition['stim'])[np.isfinite(summary_by_condition['stim'])]\n",
        "delta_data = np.array(summary_by_condition['delta'])[np.isfinite(summary_by_condition['delta'])]\n",
        "\n",
        "print(f\"  REST:  mean r = {rest_data.mean():.4f}, p = {ttest_1samp(rest_data, 0)[1]:.6f}\")\n",
        "print(f\"  STIM:  mean r = {stim_data.mean():.4f}, p = {ttest_1samp(stim_data, 0)[1]:.6f}\")\n",
        "print(f\"  DELTA: mean r = {delta_data.mean():.4f}, p = {ttest_1samp(delta_data, 0)[1]:.6f}\")\n",
        "\n",
        "print(\"\"\"\n",
        "### Part II: All-Seeds Validation\n",
        "- Repeats analysis for all 450 possible seeds\n",
        "- Indicates: What % of brain seeds show significant correlation?\n",
        "\"\"\")\n",
        "print(f\"  Average % significant seeds per target: {mean_pct_sig:.1f}% ± {std_pct_sig:.1f}%\")\n",
        "print(f\"  → Interpretation: {mean_pct_sig:.0f}% of seed regions significantly capture\")\n",
        "print(f\"     empirical-vs-simulated correlations\")\n",
        "\n",
        "print(\"\"\"\n",
        "### Part III: Full FC Matrix Validation\n",
        "- Compares entire correlation matrices (not just seeds)\n",
        "- Indicates: Overall FC pattern similarity\n",
        "\"\"\")\n",
        "rest_fc_data = np.array(fc_matrix_results['rest_fc'])[np.isfinite(fc_matrix_results['rest_fc'])]\n",
        "delta_fc_data = np.array(fc_matrix_results['delta_fc'])[np.isfinite(fc_matrix_results['delta_fc'])]\n",
        "\n",
        "if len(rest_fc_data) > 0:\n",
        "    print(f\"  REST FC:  mean r = {rest_fc_data.mean():.4f}, p = {ttest_1samp(rest_fc_data, 0)[1]:.6f}\")\n",
        "if len(delta_fc_data) > 0:\n",
        "    print(f\"  DELTA FC: mean r = {delta_fc_data.mean():.4f}, p = {ttest_1samp(delta_fc_data, 0)[1]:.6f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION: IS SIMULATED TMS RELATED TO EMPIRICAL TMS?\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Decision logic\n",
        "delta_sig = ttest_1samp(delta_data, 0)[1] < 0.05 if len(delta_data) > 0 else False\n",
        "delta_fc_sig = ttest_1samp(delta_fc_data, 0)[1] < 0.05 if len(delta_fc_data) > 0 else False\n",
        "pct_seeds_high = mean_pct_sig > 30  # If >30% of seeds are significant\n",
        "\n",
        "print(\"\\nCriteria for validation:\")\n",
        "print(f\"  1. Target-seed DELTA significant (p < 0.05): {'✓ YES' if delta_sig else '✗ NO'}\")\n",
        "print(f\"  2. Full FC DELTA significant (p < 0.05): {'✓ YES' if delta_fc_sig else '✗ NO'}\")\n",
        "print(f\"  3. >30% of seeds significant: {'✓ YES' if pct_seeds_high else '✗ NO'}\")\n",
        "\n",
        "if delta_sig and (delta_fc_sig or pct_seeds_high):\n",
        "    print(\"\"\"\n",
        "╔════════════════════════════════════════════════════════════════╗\n",
        "║ ✓ STRONG VALIDATION: YES, simulated TMS effects ARE related   ║\n",
        "║ to empirical TMS effects                                       ║\n",
        "║                                                                ║\n",
        "║ The model successfully captures TMS-induced connectivity       ║\n",
        "║ changes both at target-seed and distributed network levels.   ║\n",
        "╚════════════════════════════════════════════════════════════════╝\n",
        "\"\"\")\n",
        "elif delta_sig:\n",
        "    print(\"\"\"\n",
        "╔════════════════════════════════════════════════════════════════╗\n",
        "║ ⚠ MODERATE VALIDATION: Partial support for model validity     ║\n",
        "║                                                                ║\n",
        "║ Target-seed effects are captured, but full FC patterns show   ║\n",
        "║ limited correlation. The model may capture local effects      ║\n",
        "║ but miss distributed network reorganization.                  ║\n",
        "╚════════════════════════════════════════════════════════════════╝\n",
        "\"\"\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "╔════════════════════════════════════════════════════════════════╗\n",
        "║ ✗ LIMITED VALIDATION: Simulated effects NOT significantly     ║\n",
        "║ related to empirical effects                                   ║\n",
        "║                                                                ║\n",
        "║ The population model may be insufficient for capturing        ║\n",
        "║ TMS-specific effects. Subject-specific or hierarchical        ║\n",
        "║ models may be needed.                                          ║\n",
        "╚════════════════════════════════════════════════════════════════╝\n",
        "\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0df7f08",
      "metadata": {
        "id": "c0df7f08"
      },
      "source": [
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf1de27",
      "metadata": {
        "id": "2bf1de27"
      },
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "comprehensive_results = {\n",
        "    'metadata': {\n",
        "        'validation_type': 'Comprehensive TMS-fMRI ANN Validation',\n",
        "        'timestamp': str(pd.Timestamp.now()),\n",
        "    },\n",
        "    'part_i_target_seed': {\n",
        "        'rest_mean_r': float(rest_data.mean()),\n",
        "        'rest_p_value': float(ttest_1samp(rest_data, 0)[1]),\n",
        "        'stim_mean_r': float(stim_data.mean()),\n",
        "        'stim_p_value': float(ttest_1samp(stim_data, 0)[1]),\n",
        "        'delta_mean_r': float(delta_data.mean()),\n",
        "        'delta_p_value': float(ttest_1samp(delta_data, 0)[1]),\n",
        "        'n_observations': int(len(delta_data)),\n",
        "    },\n",
        "    'part_ii_all_seeds': {\n",
        "        'mean_pct_significant_seeds': float(mean_pct_sig),\n",
        "        'std_pct_significant_seeds': float(std_pct_sig),\n",
        "        'n_targets': int(len(df_seeds_summary)),\n",
        "        'per_target_summary': df_seeds_summary.to_dict('records'),\n",
        "    },\n",
        "    'part_iii_full_fc': df_fc_summary.to_dict('records'),\n",
        "}\n",
        "\n",
        "with open(VALIDATION_RESULTS_JSON, 'w') as f:\n",
        "    json.dump(comprehensive_results, f, indent=2)\n",
        "\n",
        "print(f\"✓ Saved comprehensive validation results to:\")\n",
        "print(f\"  {VALIDATION_RESULTS_JSON}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}