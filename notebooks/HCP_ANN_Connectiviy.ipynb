{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/HCP_ANN_Connectiviy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dBFR8fAc8KjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3af7e4-4c50-4e27-8fcb-3df2a2b204d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'BrainStim_ANN_fMRI_HCP'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 122 (delta 34), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (122/122), 22.47 MiB | 14.75 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "‚úÖ Imported NPI from: /content/BrainStim_ANN_fMRI_HCP/src\n",
            "repo_dir: /content/BrainStim_ANN_fMRI_HCP\n",
            "preproc_dir: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects\n",
            "models_dir: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects/trained_models_MLP\n",
            "\n",
            "‚úÖ Loaded preprocessed data for id_100206\n",
            "signals shape: (4680, 450)\n",
            "inputs  shape: (4677, 1350)\n",
            "targets shape: (4677, 450)\n",
            "‚úÖ Allowed model classes: ['ANN_MLP', 'ANN_CNN', 'ANN_RNN', 'ANN_VAR']\n",
            "\n",
            "‚úÖ Loaded trained model from: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects/trained_models_MLP/id_100206_MLP.pt\n",
            "ANN_MLP(\n",
            "  (func): Sequential(\n",
            "    (0): Linear(in_features=1350, out_features=900, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=900, out_features=360, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=360, out_features=450, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "üéØ Model and data successfully loaded and ready for analysis.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üì¶ Load preprocessed fMRI data + trained model (PyTorch ‚â• 2.6 SAFE version)\n",
        "# ============================================\n",
        "\n",
        "# --- 1Ô∏è‚É£ Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- 2Ô∏è‚É£ Clone your GitHub repo (contains src/NPI.py) ---\n",
        "!rm -rf /content/BrainStim_ANN_fMRI_HCP\n",
        "!git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
        "\n",
        "# --- 3Ô∏è‚É£ Define paths ---\n",
        "import os, sys\n",
        "repo_dir   = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
        "data_dir   = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
        "preproc_dir = os.path.join(data_dir, \"preprocessed_subjects\")\n",
        "models_dir  = os.path.join(preproc_dir, \"trained_models_MLP\")\n",
        "\n",
        "# Add repo to Python path so src/NPI is visible\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.append(repo_dir)\n",
        "\n",
        "# --- 4Ô∏è‚É£ Imports ---\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc\n",
        "from src import NPI\n",
        "\n",
        "print(\"‚úÖ Imported NPI from:\", os.path.join(repo_dir, \"src\"))\n",
        "print(\"repo_dir:\", repo_dir)\n",
        "print(\"preproc_dir:\", preproc_dir)\n",
        "print(\"models_dir:\", models_dir)\n",
        "\n",
        "# --- 5Ô∏è‚É£ Choose subject ID ---\n",
        "subj_id = \"id_100206\"   # üîÅ change to load another subject\n",
        "\n",
        "# --- 6Ô∏è‚É£ Define file paths ---\n",
        "signals_path = os.path.join(preproc_dir, f\"{subj_id}_signals.npy\")\n",
        "inputs_path  = os.path.join(preproc_dir, f\"{subj_id}_inputs.npy\")\n",
        "targets_path = os.path.join(preproc_dir, f\"{subj_id}_targets.npy\")\n",
        "model_path   = os.path.join(models_dir,   f\"{subj_id}_MLP.pt\")  # or \"_MLP_full.pt\" if you used that name\n",
        "\n",
        "# --- 7Ô∏è‚É£ Load preprocessed data ---\n",
        "signals = np.load(signals_path)\n",
        "inputs  = np.load(inputs_path)\n",
        "targets = np.load(targets_path)\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded preprocessed data for {subj_id}\")\n",
        "print(f\"signals shape: {signals.shape}\")\n",
        "print(f\"inputs  shape: {inputs.shape}\")\n",
        "print(f\"targets shape: {targets.shape}\")\n",
        "\n",
        "# --- 8Ô∏è‚É£ Safely allowlist your model classes (needed since PyTorch ‚â• 2.6) ---\n",
        "import torch.serialization\n",
        "\n",
        "# Find and allow all model classes defined inside NPI.py\n",
        "import re\n",
        "npi_file = os.path.join(repo_dir, \"src\", \"NPI.py\")\n",
        "with open(npi_file, \"r\") as f:\n",
        "    class_names = re.findall(r\"class\\s+([A-Za-z0-9_]+)\\s*\\(\", f.read())\n",
        "\n",
        "safe_classes = []\n",
        "for name in class_names:\n",
        "    try:\n",
        "        cls = getattr(NPI, name)\n",
        "        safe_classes.append(cls)\n",
        "    except AttributeError:\n",
        "        pass\n",
        "\n",
        "if safe_classes:\n",
        "    torch.serialization.add_safe_globals(safe_classes)\n",
        "    print(\"‚úÖ Allowed model classes:\", [c.__name__ for c in safe_classes])\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No model classes detected in NPI.py\")\n",
        "\n",
        "# --- 9Ô∏è‚É£ Load trained model (FULL MODEL saved with torch.save(model, ...)) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torch.load(model_path, map_location=device, weights_only=False)\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded trained model from: {model_path}\")\n",
        "print(model)\n",
        "\n",
        "# --- üîü Optional cleanup ---\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\nüéØ Model and data successfully loaded and ready for analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/BrainStim_ANN_fMRI_HCP\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1GhAzkhd6M9",
        "outputId": "be1a17ec-fff6-447b-8a80-57d629cd2f27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "notebooks  README.md  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6m6NAyywY0rr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}