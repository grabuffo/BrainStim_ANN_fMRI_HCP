{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/HCP_ANN_Connectiviy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dBFR8fAc8KjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe96683-d9fd-4a4a-dff7-ebc3bdc36581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'BrainStim_ANN_fMRI_HCP'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 126 (delta 35), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (126/126), 22.47 MiB | 1.33 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "‚úÖ Repo loaded from: /content/BrainStim_ANN_fMRI_HCP\n",
            "Using device: cpu\n",
            "\n",
            "================ id_100206 ================\n",
            "üß© Model loaded.\n",
            "‚úÖ EC(t) computed: (4677, 450, 450)\n",
            "üíæ Saved EC(t) ‚Üí /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects/ECts_MLP/id_100206_ECt.npy\n",
            "\n",
            "üéØ All subjects processed successfully.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üß† Compute EC(t) for each subject using NPI.model_ECt\n",
        "# ============================================\n",
        "\n",
        "# --- 1Ô∏è‚É£ Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- 2Ô∏è‚É£ Clone GitHub repo (contains src/NPI.py) ---\n",
        "!rm -rf /content/BrainStim_ANN_fMRI_HCP\n",
        "!git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
        "\n",
        "# --- 3Ô∏è‚É£ Define paths ---\n",
        "import os, sys, gc\n",
        "repo_dir    = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
        "data_dir    = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
        "preproc_dir = os.path.join(data_dir, \"preprocessed_subjects\")\n",
        "models_dir  = os.path.join(preproc_dir, \"trained_models_MLP\")\n",
        "ects_dir    = os.path.join(preproc_dir, \"ECts_MLP\")\n",
        "os.makedirs(ects_dir, exist_ok=True)\n",
        "\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.append(repo_dir)\n",
        "\n",
        "# --- 4Ô∏è‚É£ Imports ---\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.serialization\n",
        "from src import NPI\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Repo loaded from:\", repo_dir)\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --- 5Ô∏è‚É£ Choose which subjects to process ---\n",
        "# either specify manually:\n",
        "subjects = [\"id_100206\"]\n",
        "# or automatically detect all\n",
        "# subjects = sorted({fn.split(\"_signals.npy\")[0]\n",
        "#                    for fn in os.listdir(preproc_dir)\n",
        "#                    if fn.endswith(\"_signals.npy\")})\n",
        "\n",
        "# --- 6Ô∏è‚É£ Allowlist your model classes (needed for PyTorch ‚â•2.6) ---\n",
        "torch.serialization.add_safe_globals(\n",
        "    [NPI.ANN_MLP, NPI.ANN_CNN, NPI.ANN_RNN, NPI.ANN_VAR]\n",
        ")\n",
        "\n",
        "# --- 7Ô∏è‚É£ Define helper to load model (full model or checkpoint) ---\n",
        "def load_model(model_path, inputs, targets):\n",
        "    ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    if hasattr(ckpt, \"eval\"):  # full model saved with torch.save(model)\n",
        "        model = ckpt.to(device)\n",
        "        model.eval()\n",
        "        return model\n",
        "    if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "        method = ckpt.get(\"method\", \"MLP\")\n",
        "        ROI_num = ckpt.get(\"ROI_num\", targets.shape[-1])\n",
        "        using_steps = ckpt.get(\"using_steps\", inputs.shape[-2] if inputs.ndim > 1 else 1)\n",
        "        model = NPI.build_model(method, ROI_num, using_steps).to(device)\n",
        "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "        model.eval()\n",
        "        return model\n",
        "    raise ValueError(\"Unrecognized model file format\")\n",
        "\n",
        "# --- 8Ô∏è‚É£ Main EC(t) extraction loop ---\n",
        "pert_strength = 0.1\n",
        "ECts = {}\n",
        "\n",
        "for sid in subjects:\n",
        "    print(f\"\\n================ {sid} ================\")\n",
        "\n",
        "    sig_path = os.path.join(preproc_dir, f\"{sid}_signals.npy\")\n",
        "    inp_path = os.path.join(preproc_dir, f\"{sid}_inputs.npy\")\n",
        "    tgt_path = os.path.join(preproc_dir, f\"{sid}_targets.npy\")\n",
        "    mdl_path = os.path.join(models_dir,  f\"{sid}_MLP.pt\")\n",
        "\n",
        "    if not os.path.exists(sig_path) or not os.path.exists(mdl_path):\n",
        "        print(f\"‚ùå Missing data or model for {sid}\")\n",
        "        continue\n",
        "\n",
        "    # Load fMRI windows\n",
        "    Z = np.load(sig_path)             # (T, N)\n",
        "    X = np.load(inp_path)             # (M, S*N)\n",
        "    Y = np.load(tgt_path)             # (M, N)\n",
        "\n",
        "    # Load model\n",
        "    model = load_model(mdl_path, X, Y)\n",
        "    print(\"üß© Model loaded.\")\n",
        "\n",
        "    # Compute EC(t)\n",
        "    EC_t = NPI.model_ECt(model, input_X=X, target_Y=Y, pert_strength=pert_strength)\n",
        "    ECts[sid] = EC_t\n",
        "    print(f\"‚úÖ EC(t) computed: {EC_t.shape}\")\n",
        "\n",
        "    # Save\n",
        "    out_path = os.path.join(ects_dir, f\"{sid}_ECt.npy\")\n",
        "    np.save(out_path, EC_t)\n",
        "    print(f\"üíæ Saved EC(t) ‚Üí {out_path}\")\n",
        "\n",
        "    del Z, X, Y, model, EC_t\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nüéØ All subjects processed successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/BrainStim_ANN_fMRI_HCP\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1GhAzkhd6M9",
        "outputId": "be1a17ec-fff6-447b-8a80-57d629cd2f27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "notebooks  README.md  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6m6NAyywY0rr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}