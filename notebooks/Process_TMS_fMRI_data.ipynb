{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Process_TMS_fMRI_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5UJ9sEa8XCy",
    "outputId": "3c3b5c3d-ae81-4f47-8031-0dbc93005b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Repo already exists âœ…\n",
      "âœ… Environment ready!\n",
      "Repo directory: /content/BrainStim_ANN_fMRI_HCP\n",
      "Data directory: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\n"
     ]
    }
   ],
   "source": [
    "# --- Setup cell ---\n",
    "\n",
    "# 1 - Mount Drive (for data only)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# 2 - Clone repo (only if missing)\n",
    "import os\n",
    "if not os.path.exists(\"/content/BrainStim_ANN_fMRI_HCP\"):\n",
    "    !git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
    "else:\n",
    "    print(\"Repo already exists âœ…\")\n",
    "\n",
    "# 3 - Set paths\n",
    "repo_dir = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
    "data_dir = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "# 4 - Imports\n",
    "from src.preprocessing_hcp import *\n",
    "from src.NPI import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import gc\n",
    "\n",
    "print(\"âœ… Environment ready!\")\n",
    "print(\"Repo directory:\", repo_dir)\n",
    "print(\"Data directory:\", data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYb11Hib_Aq2",
    "outputId": "c642e30c-2e92-4fb3-c333-02bef0ca0970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 4 fMRI runs:\n",
      "  - REST1_LR\n",
      "  - REST1_RL\n",
      "  - REST2_LR\n",
      "  - REST2_RL\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocessing and data extraction ---\n",
    "\n",
    "# Parameters\n",
    "n_nodes = 450                # number of brain regions (parcels)\n",
    "remove_points = 30           # remove first 30 TRs\n",
    "using_steps = 3              # window length for multi2one\n",
    "number_of_subjects = 10      # or 996 if all subjects\n",
    "dtype = np.float32\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1 - Locate fMRI run files\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "run_files = {\n",
    "    \"REST1_LR\": os.path.join(data_dir, \"fmri/Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST1_LR.mat\"),\n",
    "    \"REST1_RL\": os.path.join(data_dir, \"fmri/Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST1_RL.mat\"),\n",
    "    \"REST2_LR\": os.path.join(data_dir, \"fmri/Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST2_LR.mat\"),\n",
    "    \"REST2_RL\": os.path.join(data_dir, \"fmri/Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST2_RL.mat\")\n",
    "}\n",
    "run_order = list(run_files.keys())\n",
    "\n",
    "print(f\"âœ… Found {len(run_files)} fMRI runs:\")\n",
    "for k in run_order:\n",
    "    print(\"  -\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxWjTUY1_Auo",
    "outputId": "d293b126-14b8-4fd7-9003-708fd35e35b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Found 996 subjects present in all runs.\n",
      "   â†’ Will process first 10 subjects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 2 - Find common subjects across runs\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def list_subjects(h5path, run_key):\n",
    "    \"\"\"Return list of subjects for a given run file.\"\"\"\n",
    "    with h5py.File(h5path, \"r\") as f:\n",
    "        return sorted(f[\"HCP\"][run_key].keys(), key=lambda k: int(k.split(\"_\")[-1]))\n",
    "\n",
    "subject_sets = [set(list_subjects(run_files[k], k)) for k in run_order]\n",
    "subject_ids = sorted(set.intersection(*subject_sets), key=lambda k: int(k.split(\"_\")[-1]))\n",
    "\n",
    "print(f\"\\nâœ… Found {len(subject_ids)} subjects present in all runs.\")\n",
    "subject_ids = subject_ids[:number_of_subjects]\n",
    "print(f\"   â†’ Will process first {len(subject_ids)} subjects.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VZxjV94M27S",
    "outputId": "f4f66b5b-c977-48d0-e240-66ddebca8cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Processing subject id_100206\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_100206\n",
      "\n",
      "ðŸš€ Processing subject id_100307\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_100307\n",
      "\n",
      "ðŸš€ Processing subject id_100408\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_100408\n",
      "\n",
      "ðŸš€ Processing subject id_101006\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_101006\n",
      "\n",
      "ðŸš€ Processing subject id_101107\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_101107\n",
      "\n",
      "ðŸš€ Processing subject id_101309\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_101309\n",
      "\n",
      "ðŸš€ Processing subject id_101915\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_101915\n",
      "\n",
      "ðŸš€ Processing subject id_102008\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_102008\n",
      "\n",
      "ðŸš€ Processing subject id_102109\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_102109\n",
      "\n",
      "ðŸš€ Processing subject id_102311\n",
      "      Original shape for REST1_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST1_RL: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_LR: (1200, 450) (kept as is)\n",
      "      Original shape for REST2_RL: (1200, 450) (kept as is)\n",
      "   â†’ Signals shape: (4680, 450)\n",
      "   â†’ Inputs: (4677, 1350), Targets: (4677, 450)\n",
      "   âœ… Saved preprocessed data for id_102311\n",
      "\n",
      "ðŸŽ¯ All subjects processed successfully!\n",
      "ðŸ“‚ Saved results in: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 3 - Process each subject\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "save_dir = os.path.join(data_dir, \"preprocessed_subjects\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for sid in subject_ids:\n",
    "    print(f\"ðŸš€ Processing subject {sid}\")\n",
    "    subj_runs = []\n",
    "\n",
    "    for run_key in run_order:\n",
    "        # Load fMRI time series (T, N)\n",
    "        with h5py.File(run_files[run_key], \"r\") as f:\n",
    "            ts = f[\"HCP\"][run_key][sid][\"ts\"][()]\n",
    "\n",
    "        # Print shape before and after possible transpose\n",
    "        print(f\"      Original shape for {run_key}: {ts.shape}\", end=\"\")\n",
    "        if ts.shape[0] < ts.shape[1]:\n",
    "            ts = ts.T\n",
    "            print(f\" â†’ Transposed to {ts.shape}\")\n",
    "        else:\n",
    "            print(\" (kept as is)\")\n",
    "\n",
    "        # Remove first 30 time points\n",
    "        ts = ts[remove_points:, :n_nodes]\n",
    "\n",
    "        # Apply bandpass filtering\n",
    "        ts_filt = bandpass_filter_timeseries(ts)\n",
    "        subj_runs.append(ts_filt)\n",
    "\n",
    "        # Free memory from this run\n",
    "        del ts, ts_filt\n",
    "        gc.collect()\n",
    "\n",
    "    # Concatenate all runs â†’ (T_total, N)\n",
    "    signals = np.concatenate(subj_runs, axis=0)\n",
    "    print(f\"   â†’ Signals shape: {signals.shape}\")\n",
    "\n",
    "    # Create inputs and targets\n",
    "    inputs, targets = multi2one(signals, steps=using_steps)\n",
    "    print(f\"   â†’ Inputs: {inputs.shape}, Targets: {targets.shape}\")\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(os.path.join(save_dir, f\"{sid}_signals.npy\"), signals)\n",
    "    np.save(os.path.join(save_dir, f\"{sid}_inputs.npy\"), inputs)\n",
    "    np.save(os.path.join(save_dir, f\"{sid}_targets.npy\"), targets)\n",
    "    print(f\"   âœ… Saved preprocessed data for {sid}\\n\")\n",
    "\n",
    "    # Cleanup\n",
    "    del subj_runs, signals, inputs, targets\n",
    "    gc.collect()\n",
    "\n",
    "print(\"ðŸŽ¯ All subjects processed successfully!\")\n",
    "print(f\"ðŸ“‚ Saved results in: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rm7LD7qD_A2r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcPu1hccPnmU"
   },
   "source": [
    "### Understanding `signals`, `inputs`, and `targets`\n",
    "\n",
    "Let **T** = total number of time points and **S** = number of past steps.\n",
    "\n",
    "---\n",
    "\n",
    "**`signals`**  \n",
    "- Shape: **(T, N)**  \n",
    "- Preprocessed fMRI time series (after removing first 30 TRs, filtering, and concatenating runs).  \n",
    "- `signals[t, n]` = BOLD activity of region *n* at time *t*.\n",
    "\n",
    "---\n",
    "\n",
    "**`inputs`**  \n",
    "- Shape: **(T âˆ’ S, N Ã— S)**  \n",
    "- Each row contains the flattened activity of all N regions over the past S time points.  \n",
    "- Represents the temporal context used for prediction.\n",
    "\n",
    "---\n",
    "\n",
    "**`targets`**  \n",
    "- Shape: **(T âˆ’ S, N)**  \n",
    "- Each row is the brain activity at the next time point following the input window.  \n",
    "- What the model aims to predict.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
