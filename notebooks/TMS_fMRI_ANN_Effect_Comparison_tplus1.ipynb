{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ecc2a8-48e5-4b25-b91d-c5e48ea0eadf",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/TMS_fMRI_ANN_Effect_Comparison_tplus1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5b1dd-e779-45db-a501-c053a202172d",
   "metadata": {},
   "source": [
    "# Compare empirical vs ANN stimulation effects (TMS-fMRI)\n",
    "\n",
    "Loads `stim_effects_ann_vs_emp.pkl` and for each stimulation **target parcel** computes:\n",
    "- Mean empirical effect at t+1: `emp_t1 - pre_window[-1]`\n",
    "- Mean ANN effect at t+1: `pred_stim_t1 - pred_base_t1`\n",
    "\n",
    "Then correlates these mean effect vectors per target and evaluates significance with a permutation null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 0) Mount Google Drive\n",
    "# =========================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 1) Imports + paths\n",
    "# =========================\n",
    "import os, pickle, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
    "PREPROC_ROOT = os.path.join(BASE, \"preprocessed_subjects_tms_fmri\")\n",
    "IN_DIR = os.path.join(PREPROC_ROOT, \"ANN_vs_tms_fmri\")\n",
    "\n",
    "IN_PKL = os.path.join(IN_DIR, \"stim_effects_ann_vs_emp.pkl\")\n",
    "if not os.path.exists(IN_PKL):\n",
    "    raise FileNotFoundError(f\"Cannot find {IN_PKL}. Did you run TMS_fMRI_ANN.ipynb?\")\n",
    "\n",
    "OUT_DIR = os.path.join(IN_DIR, \"effect_comparison_tplus1\")\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Loading:\", IN_PKL)\n",
    "with open(IN_PKL, \"rb\") as f:\n",
    "    stim_effects = pickle.load(f)\n",
    "\n",
    "print(\"Subjects in stim_effects:\", len(stim_effects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06acbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 2) Config\n",
    "# =========================\n",
    "N = 450                 # parcels\n",
    "N_PERM = 1000           # permutations for null distribution per target\n",
    "RANDOM_SEED = 0\n",
    "TPLUS = 1               # t+1 here; can switch to 2 later if pred_*_t2 was saved\n",
    "SAVE_TOP_K_PLOTS = 25   # how many target plots to save (sorted by p-value)\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 3) Aggregate mean effects per target\n",
    "# =========================\n",
    "mean_emp = {}\n",
    "mean_ann = {}\n",
    "counts = {}\n",
    "\n",
    "def get_emp_post(ev, tplus=1):\n",
    "    if tplus == 1: return ev[\"emp_t1\"]\n",
    "    if tplus == 2: return ev[\"emp_t2\"]\n",
    "    if tplus == 3: return ev[\"emp_t3\"]\n",
    "    raise ValueError(\"tplus must be 1,2,3\")\n",
    "\n",
    "for sub_id, targets in stim_effects.items():\n",
    "    for target_idx, events in targets.items():\n",
    "        for ev in events:\n",
    "            x_t = ev[\"pre_window\"][-1]               # (N,)\n",
    "            x_post = get_emp_post(ev, tplus=TPLUS)   # (N,)\n",
    "            eff_emp = x_post - x_t\n",
    "\n",
    "            if TPLUS == 1:\n",
    "                eff_ann = ev[\"pred_stim_t1\"] - ev[\"pred_base_t1\"]\n",
    "            elif TPLUS == 2:\n",
    "                if \"pred_stim_t2\" not in ev:\n",
    "                    continue\n",
    "                eff_ann = ev[\"pred_stim_t2\"] - ev[\"pred_base_t2\"]\n",
    "            else:\n",
    "                # no ANN t+3 saved in the upstream notebook\n",
    "                continue\n",
    "\n",
    "            if target_idx not in mean_emp:\n",
    "                mean_emp[target_idx] = np.zeros(N, dtype=np.float64)\n",
    "                mean_ann[target_idx] = np.zeros(N, dtype=np.float64)\n",
    "                counts[target_idx] = 0\n",
    "\n",
    "            mean_emp[target_idx] += eff_emp\n",
    "            mean_ann[target_idx] += eff_ann\n",
    "            counts[target_idx] += 1\n",
    "\n",
    "for t in list(mean_emp.keys()):\n",
    "    c = counts[t]\n",
    "    if c <= 0:\n",
    "        del mean_emp[t]; del mean_ann[t]; del counts[t]\n",
    "    else:\n",
    "        mean_emp[t] /= c\n",
    "        mean_ann[t] /= c\n",
    "\n",
    "print(\"Targets with data:\", len(mean_emp))\n",
    "print(\"Example (target -> count):\", list(counts.items())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 4) Correlation + permutation null per target\n",
    "# =========================\n",
    "def pearsonr_fast(x, y):\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "    x = x - x.mean()\n",
    "    y = y - y.mean()\n",
    "    denom = np.sqrt(np.sum(x*x) * np.sum(y*y))\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return float(np.sum(x*y) / denom)\n",
    "\n",
    "results = []\n",
    "\n",
    "for target_idx in sorted(mean_emp.keys()):\n",
    "    emp = mean_emp[target_idx]\n",
    "    ann = mean_ann[target_idx]\n",
    "\n",
    "    r_obs = pearsonr_fast(emp, ann)\n",
    "\n",
    "    r_null = np.empty(N_PERM, dtype=np.float64)\n",
    "    for i in range(N_PERM):\n",
    "        perm = rng.permutation(N)\n",
    "        r_null[i] = pearsonr_fast(emp, ann[perm])\n",
    "\n",
    "    p = (np.sum(np.abs(r_null) >= abs(r_obs)) + 1) / (N_PERM + 1)\n",
    "\n",
    "    results.append({\n",
    "        \"target_idx\": int(target_idx),\n",
    "        \"n_events\": int(counts[target_idx]),\n",
    "        \"r_emp_vs_ann\": r_obs,\n",
    "        \"p_perm_two_sided\": p,\n",
    "        \"null_mean\": float(np.mean(r_null)),\n",
    "        \"null_std\": float(np.std(r_null)),\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(\"p_perm_two_sided\").reset_index(drop=True)\n",
    "res_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 5) Save mean dictionaries + summary table\n",
    "# =========================\n",
    "out_emp = os.path.join(OUT_DIR, f\"mean_emp_effect_tplus{TPLUS}.pkl\")\n",
    "out_ann = os.path.join(OUT_DIR, f\"mean_ann_effect_tplus{TPLUS}.pkl\")\n",
    "out_csv = os.path.join(OUT_DIR, f\"corr_summary_tplus{TPLUS}.csv\")\n",
    "\n",
    "with open(out_emp, \"wb\") as f:\n",
    "    pickle.dump(mean_emp, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(out_ann, \"wb\") as f:\n",
    "    pickle.dump(mean_ann, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "\n",
    "cfg = {\n",
    "    \"tplus\": TPLUS,\n",
    "    \"N\": N,\n",
    "    \"N_PERM\": N_PERM,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"emp_effect\": \"emp_tplus - pre_window[-1]\",\n",
    "    \"ann_effect\": \"pred_stim_tplus - pred_base_tplus\",\n",
    "    \"input_file\": IN_PKL,\n",
    "    \"out_dir\": OUT_DIR\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", out_emp)\n",
    "print(\"Saved:\", out_ann)\n",
    "print(\"Saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 6) Plot per-target scatter with regression line\n",
    "# =========================\n",
    "def plot_scatter_with_fit(x, y, title, out_path):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(x, y, s=8, alpha=0.7)\n",
    "    xs = np.linspace(x.min(), x.max(), 200)\n",
    "    plt.plot(xs, a*xs + b, linewidth=2)\n",
    "    plt.xlabel(f\"Mean empirical effect (t+{TPLUS})\")\n",
    "    plt.ylabel(f\"Mean ANN effect (t+{TPLUS})\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "TOP_K = int(SAVE_TOP_K_PLOTS)\n",
    "for _, row in res_df.head(TOP_K).iterrows():\n",
    "    t = int(row[\"target_idx\"])\n",
    "    r = row[\"r_emp_vs_ann\"]\n",
    "    p = row[\"p_perm_two_sided\"]\n",
    "    n = int(row[\"n_events\"])\n",
    "    title = f\"Target {t} | n={n} | r={r:.3f} | p_perm={p:.4g}\"\n",
    "    out_png = os.path.join(FIG_DIR, f\"target_{t:03d}_scatter.png\")\n",
    "    plot_scatter_with_fit(mean_emp[t], mean_ann[t], title, out_png)\n",
    "\n",
    "print(f\"Saved scatter plots for TOP_K={TOP_K} targets into:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 7) Quick view: histogram of correlations\n",
    "# =========================\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(res_df[\"r_emp_vs_ann\"].dropna().values, bins=40)\n",
    "plt.xlabel(\"Correlation r (mean empirical vs mean ANN effect)\")\n",
    "plt.ylabel(\"Count (targets)\")\n",
    "plt.title(\"Distribution of target-wise correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neuro310)",
   "language": "python",
   "name": "neuro310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
