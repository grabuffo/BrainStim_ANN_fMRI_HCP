{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/TMS_fMRI_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81a8d55-addf-4a9c-90e9-359c770c535c",
      "metadata": {
        "id": "f81a8d55-addf-4a9c-90e9-359c770c535c"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/TMS_fMRI_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e11e6af-81c8-46d7-87bb-2ca30ca6f5c9",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "7e11e6af-81c8-46d7-87bb-2ca30ca6f5c9"
      },
      "source": [
        "# TMS-fMRI ANN stimulation prediction (population model)\n",
        "\n",
        "This notebook:\n",
        "- loads the **population ANN** trained on task-rest\n",
        "- loads the original TMS-fMRI `dataset_tian50_schaefer400_allruns.pkl`\n",
        "- loops over **task-stim** runs and **stimulation events**\n",
        "- extracts the **pre-stim window** (S=3 volumes)\n",
        "- predicts the next state with the ANN:\n",
        "  - **baseline** (no perturbation)\n",
        "  - **perturbed** (+0.1 on the stimulated parcel at the last time of the window)\n",
        "- also computes a 2-step rollout (saved for TR-mismatch flexibility)\n",
        "- saves results to:\n",
        "\n",
        "`/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/ANN_vs_tms_fmri/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a8d9b2cc",
      "metadata": {
        "id": "a8d9b2cc",
        "outputId": "9ec4cc7e-9742-4554-8480-48eae5fbaacd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# 0) Mount Google Drive\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "54389736",
      "metadata": {
        "id": "54389736",
        "outputId": "b4dfd164-cd4f-4a52-aaf1-b543fc4c6690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BrainStim_ANN_fMRI_HCP'...\n",
            "remote: Enumerating objects: 494, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 494 (delta 64), reused 10 (delta 10), pack-reused 350 (from 2)\u001b[K\n",
            "Receiving objects: 100% (494/494), 63.21 MiB | 13.60 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "Torch device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# 1) Clone repo + imports\n",
        "# =========================\n",
        "import os, sys, pickle, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "REPO_DIR = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
        "else:\n",
        "    print(\"Repo already exists ✅\")\n",
        "\n",
        "sys.path.append(REPO_DIR)\n",
        "\n",
        "from src.NPI import build_model, device  # uses GPU if available\n",
        "print(\"Torch device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "92a403d4",
      "metadata": {
        "id": "92a403d4",
        "outputId": "21db89ec-2a9e-4569-c656-46300dfae58d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset PKL: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/TMS_fMRI/dataset_tian50_schaefer400_allruns.pkl | exists: True\n",
            "Model dir   : /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/trained_models_MLP_tms_fmri | exists: True\n",
            "Model path  : /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/trained_models_MLP_tms_fmri/population_MLP_tms_fmri.pt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# 2) Paths (EDIT IF NEEDED)\n",
        "# =========================\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
        "\n",
        "# Original dictionary with both rest and stim runs\n",
        "DATASET_PKL = os.path.join(BASE, \"TMS_fMRI\", \"dataset_tian50_schaefer400_allruns.pkl\")\n",
        "\n",
        "# Folder where you saved preprocessed rest data + trained population model\n",
        "PREPROC_ROOT = os.path.join(BASE, \"preprocessed_subjects_tms_fmri\")\n",
        "\n",
        "# Where to save ANN-vs-empirical stimulation dictionaries\n",
        "OUT_DIR = os.path.join(PREPROC_ROOT, \"ANN_vs_tms_fmri\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Population model path (adjust if your filename differs)\n",
        "MODEL_DIR = os.path.join(PREPROC_ROOT, \"trained_models_MLP_tms_fmri\")\n",
        "MODEL_PATH_CANDIDATES = [\n",
        "    os.path.join(MODEL_DIR, \"population_MLP_tms_fmri.pt\"),\n",
        "    os.path.join(MODEL_DIR, \"population_MLP_tms_fmri.pth\"),\n",
        "    os.path.join(MODEL_DIR, \"population_MLP_tms_fmri.ptc\"),\n",
        "]\n",
        "MODEL_PATH = next((p for p in MODEL_PATH_CANDIDATES if os.path.exists(p)), None)\n",
        "\n",
        "print(\"Dataset PKL:\", DATASET_PKL, \"| exists:\", os.path.exists(DATASET_PKL))\n",
        "print(\"Model dir   :\", MODEL_DIR, \"| exists:\", os.path.exists(MODEL_DIR))\n",
        "print(\"Model path  :\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dbe3d609",
      "metadata": {
        "id": "dbe3d609"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 3) Config\n",
        "# =========================\n",
        "S = 3                   # input window length (must match training)\n",
        "N = 450                 # parcels (Tian50 + Schaefer400)\n",
        "PERTURB_AMP = 0.5       # z-scored units added to targeted parcel at last step of the window\n",
        "MAX_EMP_HORIZON = 3     # save empirical t+1..t+3 (volumes)\n",
        "SAVE_2STEP = True       # compute and save ANN 2-step rollout (recommended)\n",
        "\n",
        "# Note on TR mismatch:\n",
        "# - model trained on rest TR ~= 2.0s\n",
        "# - stim runs TR may be ~= 2.4s\n",
        "# We save 1-step and 2-step predictions for later comparison choices.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 4) Load dataset dict + model\n",
        "# =========================\n",
        "with open(DATASET_PKL, \"rb\") as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "print(\"Loaded subjects:\", len(dataset))\n",
        "\n",
        "if MODEL_PATH is None:\n",
        "    raise FileNotFoundError(\"Could not find population model file in MODEL_DIR. Please update MODEL_PATH.\")\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import torch\n",
        "\n",
        "# Build model (must match training)\n",
        "METHOD = \"MLP\"\n",
        "model = build_model(METHOD, ROI_num=N, using_steps=S).to(device)\n",
        "\n",
        "# ---- Robust load (PyTorch 2.6+ safe default change) ----\n",
        "try:\n",
        "    # First try: load weights-only state_dict (newer safe behavior)\n",
        "    state = torch.load(MODEL_PATH, map_location=device, weights_only=True)\n",
        "    if isinstance(state, dict) and \"state_dict\" in state:\n",
        "        model.load_state_dict(state[\"state_dict\"])\n",
        "    elif isinstance(state, dict):\n",
        "        model.load_state_dict(state)\n",
        "    else:\n",
        "        raise RuntimeError(\"weights_only=True returned non-dict object; falling back.\")\n",
        "    print(\"Loaded checkpoint as weights/state_dict (weights_only=True).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"weights_only=True failed, falling back to weights_only=False.\")\n",
        "    print(\"Reason:\", repr(e))\n",
        "\n",
        "    # Fallback: trust your own checkpoint and load full pickle\n",
        "    state = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "    # If it’s a dict, treat as state_dict; otherwise it’s likely a full model object\n",
        "    if isinstance(state, dict) and \"state_dict\" in state:\n",
        "        model.load_state_dict(state[\"state_dict\"])\n",
        "        print(\"Loaded state['state_dict'] (weights_only=False).\")\n",
        "    elif isinstance(state, dict):\n",
        "        model.load_state_dict(state)\n",
        "        print(\"Loaded state_dict (weights_only=False).\")\n",
        "    else:\n",
        "        model = state.to(device)\n",
        "        print(\"Loaded full model object (weights_only=False).\")\n",
        "\n",
        "model.eval()\n",
        "print(\"Model ready.\")\n"
      ],
      "metadata": {
        "id": "0fms1UZtEHFD",
        "outputId": "691dd8dc-0d83-4720-e0bd-d821e6634a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0fms1UZtEHFD",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1973822120.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  dataset = pickle.load(f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded subjects: 46\n",
            "weights_only=True failed, falling back to weights_only=False.\n",
            "Reason: UnpicklingError('Weights only load failed. This file can still be loaded, to do so you have two options, \\x1b[1mdo those steps only if you trust the source of the checkpoint\\x1b[0m. \\n\\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\\n\\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\\n\\tWeightsUnpickler error: Unsupported global: GLOBAL src.NPI.ANN_MLP was not an allowed global by default. Please use `torch.serialization.add_safe_globals([src.NPI.ANN_MLP])` or the `torch.serialization.safe_globals([src.NPI.ANN_MLP])` context manager to allowlist this global if you trust this class/function.\\n\\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.')\n",
            "Loaded full model object (weights_only=False).\n",
            "Model ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a13b7ff6",
      "metadata": {
        "id": "a13b7ff6"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 5) Helpers\n",
        "# =========================\n",
        "def get_onset_column(df: pd.DataFrame):\n",
        "    \"\"\"Infer onset column name in seconds.\"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        return None\n",
        "    candidates = [\"onset\", \"Onset\", \"stim_onset\", \"t\", \"time\", \"onset_s\", \"onset_sec\", \"seconds\"]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    # fallback: first numeric column\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[c]):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_from_window(window_SxN: np.ndarray):\n",
        "    \"\"\"window_SxN: (S,N) numpy -> returns (N,) numpy\"\"\"\n",
        "    x = torch.tensor(window_SxN.reshape(1, -1), dtype=torch.float32, device=device)  # (1, S*N)\n",
        "    y = model(x)  # (1, N)\n",
        "    return y.detach().cpu().numpy().squeeze(0)\n",
        "\n",
        "def rollout_2step(window_SxN: np.ndarray):\n",
        "    \"\"\"returns (pred_t1, pred_t2) each (N,)\"\"\"\n",
        "    pred1 = predict_from_window(window_SxN)\n",
        "    w2 = np.vstack([window_SxN[1:], pred1[None, :]])  # shift window, append pred1\n",
        "    pred2 = predict_from_window(w2)\n",
        "    return pred1, pred2\n",
        "\n",
        "def safe_target_idx(target_vec):\n",
        "    \"\"\"Return 0-based target index if exactly one 1 else None.\"\"\"\n",
        "    if target_vec is None:\n",
        "        return None\n",
        "    v = np.asarray(target_vec).astype(int).ravel()\n",
        "    if v.size == 0 or v.sum() != 1:\n",
        "        return None\n",
        "    return int(np.argmax(v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "623d8ab0",
      "metadata": {
        "id": "623d8ab0",
        "outputId": "7f4e64cd-c62c-4474-9d3c-0b97e32e735e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runs processed: 432\n",
            "Events total in TSVs: 29376\n",
            "Events saved: 29376\n",
            "Events skipped: 0\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 6) Main loop: build stimulation dictionaries\n",
        "# =========================\n",
        "stim_effects = {}  # stim_effects[sub_id][target_idx] = list of event dicts\n",
        "\n",
        "n_runs = 0\n",
        "n_events_total = 0\n",
        "n_events_used = 0\n",
        "n_events_skipped = 0\n",
        "\n",
        "for sub_id, sub_data in dataset.items():\n",
        "    if \"task-stim\" not in sub_data:\n",
        "        continue\n",
        "\n",
        "    stim_effects[sub_id] = {}\n",
        "    stim_runs = sub_data[\"task-stim\"]  # int-keyed dict of runs\n",
        "\n",
        "    for run_idx, run in stim_runs.items():\n",
        "        n_runs += 1\n",
        "\n",
        "        ts = run.get(\"time series\", None)\n",
        "        md = run.get(\"metadata\", {}) or {}\n",
        "        target_vec = run.get(\"target\", None)\n",
        "        events_df = run.get(\"stim time\", None)\n",
        "\n",
        "        if ts is None or not isinstance(ts, np.ndarray) or ts.ndim != 2:\n",
        "            n_events_skipped += 1\n",
        "            continue\n",
        "        if ts.shape[1] != N:\n",
        "            raise ValueError(f\"{sub_id} run {run_idx}: expected N={N}, got {ts.shape[1]}\")\n",
        "\n",
        "        target_idx = safe_target_idx(target_vec)\n",
        "        if target_idx is None:\n",
        "            n_events_skipped += 1\n",
        "            continue\n",
        "\n",
        "        if not isinstance(events_df, pd.DataFrame) or len(events_df) == 0:\n",
        "            n_events_skipped += 1\n",
        "            continue\n",
        "\n",
        "        onset_col = get_onset_column(events_df)\n",
        "        if onset_col is None:\n",
        "            n_events_skipped += 1\n",
        "            continue\n",
        "\n",
        "        tr_s = float(md.get(\"tr_s\", 2.4))\n",
        "        onsets = events_df[onset_col].astype(float).values\n",
        "        n_events_total += len(onsets)\n",
        "\n",
        "        stim_effects[sub_id].setdefault(target_idx, [])\n",
        "\n",
        "        for onset_s in onsets:\n",
        "            # k_pre: last volume BEFORE stimulation onset\n",
        "            k_pre = int(np.floor(onset_s / tr_s) - 1)\n",
        "\n",
        "            # need window [k_pre-S+1 .. k_pre] and empirical up to k_pre+3\n",
        "            if (k_pre - (S - 1)) < 0:\n",
        "                n_events_skipped += 1\n",
        "                continue\n",
        "            if (k_pre + MAX_EMP_HORIZON) >= ts.shape[0]:\n",
        "                n_events_skipped += 1\n",
        "                continue\n",
        "\n",
        "            w_pre = ts[k_pre - (S - 1): k_pre + 1, :]  # (S,N)\n",
        "\n",
        "            # baseline preds\n",
        "            if SAVE_2STEP:\n",
        "                pred_base_t1, pred_base_t2 = rollout_2step(w_pre)\n",
        "            else:\n",
        "                pred_base_t1 = predict_from_window(w_pre)\n",
        "                pred_base_t2 = None\n",
        "\n",
        "            # perturbed: add at last step only\n",
        "            w_stim = w_pre.copy()\n",
        "            w_stim[-1, target_idx] += PERTURB_AMP\n",
        "\n",
        "            if SAVE_2STEP:\n",
        "                pred_stim_t1, pred_stim_t2 = rollout_2step(w_stim)\n",
        "            else:\n",
        "                pred_stim_t1 = predict_from_window(w_stim)\n",
        "                pred_stim_t2 = None\n",
        "\n",
        "            # empirical post states (volumes)\n",
        "            emp_t1 = ts[k_pre + 1, :].copy()\n",
        "            emp_t2 = ts[k_pre + 2, :].copy()\n",
        "            emp_t3 = ts[k_pre + 3, :].copy()\n",
        "\n",
        "            ev = {\n",
        "                \"sub_id\": sub_id,\n",
        "                \"run_idx\": int(run_idx),\n",
        "                \"session\": md.get(\"session\", None),\n",
        "                \"stim_mni_xyz\": md.get(\"stim_mni_xyz\", None),\n",
        "                \"tr_s\": tr_s,\n",
        "                \"onset_s\": float(onset_s),\n",
        "                \"k_pre\": int(k_pre),\n",
        "                \"S\": int(S),\n",
        "                \"target_idx\": int(target_idx),\n",
        "                \"perturb_amp\": float(PERTURB_AMP),\n",
        "\n",
        "                \"pre_window\": w_pre.astype(np.float32),\n",
        "\n",
        "                \"emp_t1\": emp_t1.astype(np.float32),\n",
        "                \"emp_t2\": emp_t2.astype(np.float32),\n",
        "                \"emp_t3\": emp_t3.astype(np.float32),\n",
        "\n",
        "                \"pred_base_t1\": pred_base_t1.astype(np.float32),\n",
        "                \"pred_stim_t1\": pred_stim_t1.astype(np.float32),\n",
        "            }\n",
        "            if SAVE_2STEP:\n",
        "                ev[\"pred_base_t2\"] = pred_base_t2.astype(np.float32)\n",
        "                ev[\"pred_stim_t2\"] = pred_stim_t2.astype(np.float32)\n",
        "\n",
        "            stim_effects[sub_id][target_idx].append(ev)\n",
        "            n_events_used += 1\n",
        "\n",
        "print(\"Runs processed:\", n_runs)\n",
        "print(\"Events total in TSVs:\", n_events_total)\n",
        "print(\"Events saved:\", n_events_used)\n",
        "print(\"Events skipped:\", n_events_skipped)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6bec5565",
      "metadata": {
        "id": "6bec5565",
        "outputId": "758fa11d-621f-4ffe-f1e8-ebbe6b415207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/ANN_vs_tms_fmri/stim_effects_ann_vs_emp.pkl\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/ANN_vs_tms_fmri/stim_effects_index.csv\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data/preprocessed_subjects_tms_fmri/ANN_vs_tms_fmri/config.json\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 7) Save outputs\n",
        "# =========================\n",
        "import datetime\n",
        "\n",
        "out_pkl = os.path.join(OUT_DIR, \"stim_effects_ann_vs_emp.pkl\")\n",
        "with open(out_pkl, \"wb\") as f:\n",
        "    pickle.dump(stim_effects, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Lightweight CSV index (one row per event)\n",
        "rows = []\n",
        "for sub_id, targets in stim_effects.items():\n",
        "    for target_idx, events in targets.items():\n",
        "        for e in events:\n",
        "            rows.append({\n",
        "                \"sub_id\": sub_id,\n",
        "                \"target_idx\": target_idx,\n",
        "                \"run_idx\": e[\"run_idx\"],\n",
        "                \"session\": e.get(\"session\"),\n",
        "                \"onset_s\": e[\"onset_s\"],\n",
        "                \"k_pre\": e[\"k_pre\"],\n",
        "                \"tr_s\": e[\"tr_s\"],\n",
        "                \"stim_mni_xyz\": str(e.get(\"stim_mni_xyz\")),\n",
        "            })\n",
        "\n",
        "idx_csv = os.path.join(OUT_DIR, \"stim_effects_index.csv\")\n",
        "pd.DataFrame(rows).to_csv(idx_csv, index=False)\n",
        "\n",
        "cfg = {\n",
        "    \"created_at\": datetime.datetime.now().isoformat(),\n",
        "    \"dataset_pkl\": DATASET_PKL,\n",
        "    \"model_path\": MODEL_PATH,\n",
        "    \"method\": METHOD,\n",
        "    \"S\": S,\n",
        "    \"N\": N,\n",
        "    \"perturb_amp\": PERTURB_AMP,\n",
        "    \"max_emp_horizon\": MAX_EMP_HORIZON,\n",
        "    \"save_2step\": SAVE_2STEP,\n",
        "    \"out_dir\": OUT_DIR,\n",
        "}\n",
        "with open(os.path.join(OUT_DIR, \"config.json\"), \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", out_pkl)\n",
        "print(\"Saved:\", idx_csv)\n",
        "print(\"Saved:\", os.path.join(OUT_DIR, \"config.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c4a33b49",
      "metadata": {
        "id": "c4a33b49",
        "outputId": "0445eab9-e4f8-46e4-f88b-6bd31238c678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example subject: sub-NTHC1001\n",
            "Targets: [401] ...\n",
            "Example event keys: ['sub_id', 'run_idx', 'session', 'stim_mni_xyz', 'tr_s', 'onset_s', 'k_pre', 'S', 'target_idx', 'perturb_amp', 'pre_window', 'emp_t1', 'emp_t2', 'emp_t3', 'pred_base_t1', 'pred_stim_t1', 'pred_base_t2', 'pred_stim_t2']\n",
            "pre_window shape: (3, 450)\n",
            "pred_base_t1 shape: (450,)\n",
            "pred_base_t2 shape: (450,)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 8) Quick sanity peek\n",
        "# =========================\n",
        "sub0 = next(iter(stim_effects.keys()), None)\n",
        "if sub0:\n",
        "    print(\"Example subject:\", sub0)\n",
        "    targets = stim_effects[sub0]\n",
        "    print(\"Targets:\", list(targets.keys())[:10], \"...\")\n",
        "    t0 = next(iter(targets.keys()), None)\n",
        "    if t0 is not None and len(targets[t0]) > 0:\n",
        "        e0 = targets[t0][0]\n",
        "        print(\"Example event keys:\", list(e0.keys()))\n",
        "        print(\"pre_window shape:\", e0[\"pre_window\"].shape)\n",
        "        print(\"pred_base_t1 shape:\", e0[\"pred_base_t1\"].shape)\n",
        "        if \"pred_base_t2\" in e0:\n",
        "            print(\"pred_base_t2 shape:\", e0[\"pred_base_t2\"].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stim_effects.keys()"
      ],
      "metadata": {
        "id": "IQbPr8MPEvAv",
        "outputId": "a669b59e-31c9-4e08-f6f7-13e7a2066746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IQbPr8MPEvAv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sub-NTHC1001', 'sub-NTHC1003', 'sub-NTHC1009', 'sub-NTHC1015', 'sub-NTHC1016', 'sub-NTHC1019', 'sub-NTHC1021', 'sub-NTHC1022', 'sub-NTHC1023', 'sub-NTHC1024', 'sub-NTHC1026', 'sub-NTHC1027', 'sub-NTHC1028', 'sub-NTHC1029', 'sub-NTHC1032', 'sub-NTHC1035', 'sub-NTHC1036', 'sub-NTHC1037', 'sub-NTHC1038', 'sub-NTHC1039', 'sub-NTHC1040', 'sub-NTHC1043', 'sub-NTHC1047', 'sub-NTHC1049', 'sub-NTHC1050', 'sub-NTHC1052', 'sub-NTHC1053', 'sub-NTHC1055', 'sub-NTHC1056', 'sub-NTHC1057', 'sub-NTHC1061', 'sub-NTHC1062', 'sub-NTHC1064', 'sub-NTHC1065', 'sub-NTHC1066', 'sub-NTHC1068', 'sub-NTHC1073', 'sub-NTHC1075', 'sub-NTHC1097', 'sub-NTHC1098', 'sub-NTHC1099', 'sub-NTHC1101', 'sub-NTHC1102', 'sub-NTHC1105', 'sub-NTHC1107', 'sub-NTHC1108'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stim_effects['sub-NTHC1108'][392][0].keys()"
      ],
      "metadata": {
        "id": "wmBP9OWkEkO4",
        "outputId": "33041688-72cd-462a-de21-e37cfeeebea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wmBP9OWkEkO4",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sub_id', 'run_idx', 'session', 'stim_mni_xyz', 'tr_s', 'onset_s', 'k_pre', 'S', 'target_idx', 'perturb_amp', 'pre_window', 'emp_t1', 'emp_t2', 'emp_t3', 'pred_base_t1', 'pred_stim_t1', 'pred_base_t2', 'pred_stim_t2'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHchsTw3ExiZ"
      },
      "id": "KHchsTw3ExiZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (neuro310)",
      "language": "python",
      "name": "neuro310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}