{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJZpVdhHrg-3",
        "outputId": "6e40c75b-6b1d-4f5c-8a1d-8198ff0c8d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup & Imports ----------------------------------------------------------\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os, sys\n",
        "import pickle\n",
        "from scipy import stats\n",
        "import scipy.io as sio\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, linregress\n",
        "# Point Python to your src/ folder\n",
        "sys.path.append(os.path.abspath(\"/content/drive/MyDrive/0.Estudis/3.CBC/Projects/BrainStim_ANN-main/src\"))\n",
        "\n",
        "from preprocessing import *\n",
        "from NPI import *\n",
        "from group_analysis import *\n",
        "from connectivity import *"
      ],
      "metadata": {
        "id": "rQ3Ke7lzrqXE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Import fMRI data (HCP)"
      ],
      "metadata": {
        "id": "KdvvdPUHCU3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mat73"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtBG0GrjEh6R",
        "outputId": "0c40543d-e341-471c-b22d-b2ff2de94eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mat73 in /usr/local/lib/python3.12/dist-packages (0.65)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from mat73) (3.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mat73) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc, h5py, numpy as np\n",
        "from numpy.lib.format import open_memmap\n",
        "\n",
        "base_dir = os.path.abspath('/content/drive/MyDrive/0.Estudis/3.CBC/Projects/BrainStim_ANN-main/')\n",
        "run_files = {\n",
        "    \"REST1_LR\": os.path.join(base_dir, \"data\", \"fmri\", \"Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST1_LR.mat\"),\n",
        "    \"REST1_RL\": os.path.join(base_dir, \"data\", \"fmri\", \"Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST1_RL.mat\"),\n",
        "    \"REST2_LR\": os.path.join(base_dir, \"data\", \"fmri\", \"Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST2_LR.mat\"),\n",
        "    \"REST2_RL\": os.path.join(base_dir, \"data\", \"fmri\", \"Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3_REST2_RL.mat\")\n",
        "}\n",
        "run_order = [\"REST1_LR\", \"REST1_RL\", \"REST2_LR\", \"REST2_RL\"]\n",
        "\n",
        "PAD_POLICY = \"trim\"   # \"pad\" (pad to T_max with NaN) or \"trim\" (trim to T_min)\n",
        "dtype = np.float32\n",
        "out_path = os.path.join(base_dir, \"data\", \"fmri\", \"HCP_concat_ts.npy\")\n",
        "\n",
        "def list_subjects(h5path, run_key):\n",
        "    with h5py.File(h5path, \"r\") as f:\n",
        "        return sorted(f[\"HCP\"][run_key].keys(), key=lambda k: int(k.split(\"_\")[-1]))\n",
        "\n",
        "subject_sets = [set(list_subjects(run_files[k], k)) for k in run_order]\n",
        "subject_ids = sorted(set.intersection(*subject_sets), key=lambda k: int(k.split(\"_\")[-1]))\n",
        "n_subj = len(subject_ids)\n",
        "\n",
        "with h5py.File(run_files[run_order[0]], \"r\") as f0:\n",
        "    ds0 = f0[\"HCP\"][run_order[0]][subject_ids[0]][\"ts\"]\n",
        "    if ds0.shape[0] <= ds0.shape[1]:\n",
        "        nodes_axis, time_axis = 0, 1\n",
        "    else:\n",
        "        nodes_axis, time_axis = 1, 0\n",
        "    n_nodes = ds0.shape[nodes_axis]\n",
        "\n",
        "# ---- First pass: gather per-run T targets (T_max or T_min across common subjects)\n",
        "T_targets = []\n",
        "per_run_subject_T = {}  # optional diagnostics\n",
        "for run_key in run_order:\n",
        "    Ts = []\n",
        "    with h5py.File(run_files[run_key], \"r\") as f:\n",
        "        grp = f[\"HCP\"][run_key]\n",
        "        for sid in subject_ids:\n",
        "            ds = grp[sid][\"ts\"]\n",
        "            assert ds.shape[nodes_axis] == n_nodes, f\"Node mismatch in {run_key} / {sid}\"\n",
        "            Ts.append(ds.shape[time_axis])\n",
        "    per_run_subject_T[run_key] = Ts\n",
        "    if PAD_POLICY == \"pad\":\n",
        "        T_targets.append(max(Ts))  # pad up to the longest\n",
        "    else:\n",
        "        T_targets.append(min(Ts))  # trim down to the shortest\n",
        "\n",
        "total_T = int(np.sum(T_targets))\n",
        "\n",
        "# ---- Preallocate on-disk memmap and fill with NaN\n",
        "out = open_memmap(out_path, mode=\"w+\", dtype=dtype, shape=(n_subj, n_nodes, total_T))\n",
        "out[:] = np.nan  # ensures any padding remains NaN on disk\n",
        "\n",
        "sid2idx = {sid: i for i, sid in enumerate(subject_ids)}\n",
        "\n",
        "# ---- Second pass: write data run-by-run, subject-by-subject with pad/trim\n",
        "t0 = 0\n",
        "for run_key, T_target in zip(run_order, T_targets):\n",
        "    print(f\"{run_key}: target length {T_target} (policy={PAD_POLICY})\")\n",
        "    with h5py.File(run_files[run_key], \"r\") as f:\n",
        "        grp = f[\"HCP\"][run_key]\n",
        "        for sid in subject_ids:\n",
        "            ds = grp[sid][\"ts\"]\n",
        "            arr = ds[()]\n",
        "            if nodes_axis == 1:\n",
        "                arr = arr.T  # make (nodes, time)\n",
        "            arr = arr.astype(dtype, copy=False)\n",
        "\n",
        "            t_len = arr.shape[1]\n",
        "            if PAD_POLICY == \"pad\":\n",
        "                # write as much as we have (rest already NaN)\n",
        "                L = min(t_len, T_target)\n",
        "                out[sid2idx[sid], :, t0:t0+L] = arr[:, :L]\n",
        "                # if t_len > T_target, silently truncate to target\n",
        "            else:  # \"trim\"\n",
        "                # trim to exactly T_target\n",
        "                if t_len < T_target:\n",
        "                    # optional: skip this subject or raise; here we pad to NaN just for consistency\n",
        "                    # but then the run would effectively be shorter for this subject.\n",
        "                    # Better: choose PAD_POLICY=\"pad\" for heterogeneous lengths.\n",
        "                    pass\n",
        "                L = min(t_len, T_target)\n",
        "                out[sid2idx[sid], :, t0:t0+L] = arr[:, :L]\n",
        "\n",
        "            del arr\n",
        "            gc.collect()\n",
        "    t0 += T_target\n",
        "    gc.collect()\n",
        "\n",
        "# Finish\n",
        "del out\n",
        "gc.collect()\n",
        "print(\"Done. On-disk array:\", out_path)\n"
      ],
      "metadata": {
        "id": "39AADJg-WcLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run from here!"
      ],
      "metadata": {
        "id": "5Vz6ZFKOsEqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np\n",
        "\n",
        "base_dir = os.path.abspath('/content/drive/MyDrive/0.Estudis/3.CBC/Projects/BrainStim_ANN-main/')\n",
        "out_path = os.path.join(base_dir, \"data\", \"fmri\", \"HCP_concat_ts.npy\")\n",
        "\n",
        "X = np.load(out_path, mmap_mode=\"r\")   # shape: (S, N, T)\n",
        "\n",
        "subjects = [X[i].transpose(1, 0) for i in range(X.shape[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD33yBdxaBrq",
        "outputId": "5dbbdebb-067d-47c2-a51c-2376fd7196a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2900, 450)\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = preprocess_groups(subjects)"
      ],
      "metadata": {
        "id": "JoyG0hCzsyM5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups = {\"HCP\": subjects}\n",
        "\n",
        "print(subjects[0].shape)  #(T, N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAtI7TUs1kc",
        "outputId": "1e56a03f-9239-487c-b63d-9e601cac2509"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2900, 450)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = train_models_for_groups(\n",
        "    groups,\n",
        "    steps=3,\n",
        "    batch_size=50,\n",
        "    train_prop=0.8,\n",
        "    num_epochs=100,\n",
        "    lr=1e-3,\n",
        "    l2=5e-5,\n",
        "    min_windows=50,\n",
        "    save_dir=os.path.join(base_dir, \"models\"),\n",
        "    save_prefix=\"ANN_subject\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "FF7sN3uvp6Ay",
        "outputId": "285c57da-0ecd-429e-8485-5b21e0429eb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Group: HCP — 1002 subjects ===\n",
            "[OK]  HCP[0] — T=2900, N=450, W=2897 | final train=0.065942, test=0.352331 (149.0s)\n",
            "[OK]  HCP[1] — T=2900, N=450, W=2897 | final train=0.403358, test=0.478631 (157.8s)\n",
            "[OK]  HCP[2] — T=2900, N=450, W=2897 | final train=0.103200, test=0.294534 (184.8s)\n",
            "[OK]  HCP[3] — T=2900, N=450, W=2897 | final train=0.307343, test=0.428453 (154.5s)\n",
            "[OK]  HCP[4] — T=2900, N=450, W=2897 | final train=0.143008, test=0.168261 (212.2s)\n",
            "[OK]  HCP[5] — T=2900, N=450, W=2897 | final train=0.078918, test=0.325198 (174.8s)\n",
            "[OK]  HCP[6] — T=2900, N=450, W=2897 | final train=0.237352, test=0.309079 (152.7s)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1568140879.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = train_models_for_groups(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/0.Estudis/3.CBC/Projects/BrainStim_ANN-main/src/group_analysis.py\u001b[0m in \u001b[0;36mtrain_models_for_groups\u001b[0;34m(groups, steps, hidden_rule, latent_rule, batch_size, train_prop, num_epochs, lr, l2, min_windows, save_dir, save_prefix)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             model, train_loss_hist, test_loss_hist = train_NN(\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/0.Estudis/3.CBC/Projects/BrainStim_ANN-main/src/NPI.py\u001b[0m in \u001b[0;36mtrain_NN\u001b[0;34m(model, input_X, target_Y, batch_size, train_set_proportion, num_epochs, lr, l2)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# ---- Evaluate ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Optimizer.step#{self.__class__.__name__}.step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0;31m# call optimizer step pre hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 for pre_hook in chain(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;31m# that are named \"self\". This way, all the aten ops can be called by kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# When any inputs are FakeScriptObject, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;31m# skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m_must_dispatch_in_python\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m     return pytree.tree_any(\n\u001b[0m\u001b[1;32m   1118\u001b[0m         lambda obj: isinstance(\n\u001b[1;32m   1119\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_class_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFakeScriptObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py\u001b[0m in \u001b[0;36mtree_any\u001b[0;34m(pred, tree, is_leaf)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m def tree_any(\n\u001b[0m\u001b[1;32m   1646\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPyTree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4,3))\n",
        "plt.plot(results['CNT'][0]['history']['train_loss'],label='train_loss')\n",
        "plt.plot(results['CNT'][0]['history']['test_loss'],label='test_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Training epochs')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "p7sP42i3vokB",
        "outputId": "79612f1c-04d0-49d6-97ce-a51890dbf0d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3681808877.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CNT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}