{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "855f1d16",
      "metadata": {
        "id": "855f1d16"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Reduce_effects_variability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1111bb2",
      "metadata": {
        "id": "e1111bb2"
      },
      "source": [
        "# Bifocal Stimulation: Reducing Neural Response Variability\n",
        "\n",
        "This notebook analyzes how bifocal (dual-region) stimulation can reduce response variability compared to single-region stimulation, and compares it to closed-loop state-dependent stimulation approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3aabc923",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aabc923",
        "outputId": "03cbd549-360d-4c87-eecf-4cf1d746c26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'BrainStim_ANN_fMRI_HCP'...\n",
            "remote: Enumerating objects: 341, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 341 (delta 72), reused 10 (delta 10), pack-reused 173 (from 1)\u001b[K\n",
            "Receiving objects: 100% (341/341), 31.59 MiB | 24.96 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n",
            "‚úÖ Repo loaded from: /content/BrainStim_ANN_fMRI_HCP\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# --- 1Ô∏è‚É£ Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- 2Ô∏è‚É£ Clone GitHub repo (contains src/NPI.py) ---\n",
        "!rm -rf /content/BrainStim_ANN_fMRI_HCP\n",
        "!git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git\n",
        "\n",
        "# --- 3Ô∏è‚É£ Define paths ---\n",
        "import os, sys, gc\n",
        "repo_dir    = \"/content/BrainStim_ANN_fMRI_HCP\"\n",
        "data_dir    = \"/content/drive/MyDrive/Colab Notebooks/Brain_Stim_ANN/data\"\n",
        "preproc_dir = os.path.join(data_dir, \"preprocessed_subjects\")\n",
        "models_dir  = os.path.join(preproc_dir, \"trained_models_MLP\")\n",
        "ects_dir    = os.path.join(preproc_dir, \"ECts_MLP\")\n",
        "os.makedirs(ects_dir, exist_ok=True)\n",
        "\n",
        "if repo_dir not in sys.path:\n",
        "    sys.path.append(repo_dir)\n",
        "\n",
        "# --- 4Ô∏è‚É£ Imports ---\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import torch\n",
        "import torch.serialization\n",
        "from src import NPI\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Repo loaded from:\", repo_dir)\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --- 5Ô∏è‚É£ Choose which subjects to process ---\n",
        "# either specify manually:\n",
        "#subjects = [\"id_100206\"]\n",
        "# or automatically detect all\n",
        "subjects = sorted({fn.split(\"_signals.npy\")[0]\n",
        "                   for fn in os.listdir(preproc_dir)\n",
        "                   if fn.endswith(\"_signals.npy\")})\n",
        "\n",
        "# --- 6Ô∏è‚É£ Allowlist your model classes (needed for PyTorch ‚â•2.6) ---\n",
        "torch.serialization.add_safe_globals(\n",
        "    [NPI.ANN_MLP, NPI.ANN_CNN, NPI.ANN_RNN, NPI.ANN_VAR]\n",
        ")\n",
        "\n",
        "# --- 7Ô∏è‚É£ Define helper to load model (full model or checkpoint) ---\n",
        "def load_model(model_path, inputs, targets):\n",
        "    ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    if hasattr(ckpt, \"eval\"):  # full model saved with torch.save(model)\n",
        "        model = ckpt.to(device)\n",
        "        model.eval()\n",
        "        return model\n",
        "    if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "        method = ckpt.get(\"method\", \"MLP\")\n",
        "        ROI_num = ckpt.get(\"ROI_num\", targets.shape[-1])\n",
        "        using_steps = ckpt.get(\"using_steps\", inputs.shape[-2] if inputs.ndim > 1 else 1)\n",
        "        model = NPI.build_model(method, ROI_num, using_steps).to(device)\n",
        "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "        model.eval()\n",
        "        return model\n",
        "    raise ValueError(\"Unrecognized model file format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f40046",
      "metadata": {
        "id": "73f40046"
      },
      "source": [
        "## 2. Compute Bifocal Effective Connectivity (BECt)\n",
        "\n",
        "Compute bifocal effective connectivity for all subjects using trained surrogate models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6312202",
      "metadata": {
        "id": "b6312202"
      },
      "outputs": [],
      "source": [
        "# --- 8Ô∏è‚É£ Main BEC(t) extraction loop ---\n",
        "pert_strength = 0.1\n",
        "BECts = {}\n",
        "\n",
        "for sid in subjects:\n",
        "    print(f\"\\n================ {sid} ================\")\n",
        "\n",
        "    sig_path = os.path.join(preproc_dir, f\"{sid}_signals.npy\")\n",
        "    inp_path = os.path.join(preproc_dir, f\"{sid}_inputs.npy\")\n",
        "    tgt_path = os.path.join(preproc_dir, f\"{sid}_targets.npy\")\n",
        "    mdl_path = os.path.join(models_dir,  f\"{sid}_MLP.pt\")\n",
        "\n",
        "    if not os.path.exists(sig_path) or not os.path.exists(mdl_path):\n",
        "        print(f\"‚ùå Missing data or model for {sid}\")\n",
        "        continue\n",
        "\n",
        "    # Load fMRI windows\n",
        "    Z = np.load(sig_path)             # (T, N)\n",
        "    X = np.load(inp_path)             # (M, S*N)\n",
        "    Y = np.load(tgt_path)             # (M, N)\n",
        "\n",
        "    # Load model\n",
        "    model = load_model(mdl_path, X, Y)\n",
        "    print(\"üß© Model loaded.\")\n",
        "\n",
        "    # Compute EC(t)\n",
        "    BEC_t = NPI.model_BECt(model, input_X=X[:500,:], target_Y=Y[:500,:], pert_strength=pert_strength, metric='l2')\n",
        "    BECts[sid] = BEC_t\n",
        "    print(f\"‚úÖ BEC(t) computed: {BEC_t.shape}\")\n",
        "\n",
        "    # Save\n",
        "    out_path = os.path.join(ects_dir, f\"{sid}_BECt.npy\")\n",
        "    np.save(out_path, BEC_t)\n",
        "    print(f\"üíæ Saved BEC(t) ‚Üí {out_path}\")\n",
        "\n",
        "    del Z, X, Y, model, BEC_t\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nüéØ All subjects processed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cae27c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 9Ô∏è‚É£ Load previously saved BECt files ---\n",
        "print(\"Loading previously computed BECt files...\")\n",
        "print(f\"Looking in: {ects_dir}\\n\")\n",
        "\n",
        "BECts_loaded = {}\n",
        "for fn in os.listdir(ects_dir):\n",
        "    if fn.endswith(\"_BECt.npy\"):\n",
        "        sid = fn.replace(\"_BECt.npy\", \"\")\n",
        "        path = os.path.join(ects_dir, fn)\n",
        "        try:\n",
        "            BEC_t = np.load(path)\n",
        "            BECts_loaded[sid] = BEC_t\n",
        "            print(f\"‚úì Loaded {sid}: shape {BEC_t.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Failed to load {sid}: {e}\")\n",
        "\n",
        "# Merge with newly computed (newly computed take precedence if duplicate)\n",
        "BECts.update(BECts_loaded)\n",
        "\n",
        "print(f\"\\nüìä Total BECt matrices available: {len(BECts)}\")\n",
        "print(f\"   From computation: {len([k for k in BECts.keys() if k in locals().get('subjects', [])])}\")\n",
        "print(f\"   From disk: {len(BECts_loaded)}\")\n",
        "if len(BECts) == 0:\n",
        "    print(\"‚ö†Ô∏è  No BECt data available. Run computation cell above or check ects_dir path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34140e6",
      "metadata": {
        "id": "d34140e6"
      },
      "source": [
        "## 3. Analyze Bifocal Effects on Variability Reduction\n",
        "\n",
        "Compare bifocal stimulation effects across subjects and conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a508fcf4",
      "metadata": {
        "id": "a508fcf4"
      },
      "outputs": [],
      "source": [
        "def variability_cosine(effects: np.ndarray) -> float:\n",
        "    \"\"\"1 - mean cosine similarity across samples (higher = more variable).\"\"\"\n",
        "    if effects.shape[0] < 2:\n",
        "        return np.nan\n",
        "    norms = np.linalg.norm(effects, axis=1, keepdims=True)\n",
        "    norms = np.where(norms < 1e-12, 1.0, norms)\n",
        "    Xn = effects / norms\n",
        "    S = Xn @ Xn.T\n",
        "    iu = np.triu_indices_from(S, k=1)\n",
        "    return 1.0 - np.mean(S[iu]) if len(iu[0]) > 0 else np.nan\n",
        "\n",
        "def variability_L2(effects: np.ndarray) -> float:\n",
        "    \"\"\"Mean pairwise L2 distance across samples.\"\"\"\n",
        "    if effects.shape[0] < 2:\n",
        "        return np.nan\n",
        "    diffs = effects[:, None, :] - effects[None, :, :]\n",
        "    D = np.linalg.norm(diffs, axis=2)\n",
        "    iu = np.triu_indices_from(D, k=1)\n",
        "    return np.mean(D[iu]) if len(iu[0]) > 0 else np.nan\n",
        "\n",
        "def analyze_bifocal_variability_reduction(BEC_t):\n",
        "    \"\"\"\n",
        "    Analyze how bifocal perturbations reduce neural response variability.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    BEC_t : ndarray, shape (M, N, N)\n",
        "        Bifocal effective connectivity tensor (M samples, N regions)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Analysis results including top region pairs and energy efficiency\n",
        "    \"\"\"\n",
        "    M, N, _ = BEC_t.shape\n",
        "\n",
        "    # Compute mean bifocal effect per region pair across time\n",
        "    mean_bec = np.mean(BEC_t, axis=0)  # (N, N)\n",
        "\n",
        "    # Find top region pairs for bifocal targeting\n",
        "    top_pairs = []\n",
        "    for i in range(N):\n",
        "        for j in range(i+1, N):\n",
        "            top_pairs.append({\n",
        "                'regions': (i, j),\n",
        "                'mean_effect': mean_bec[i, j],\n",
        "                'std_effect': np.std(BEC_t[:, i, j]),\n",
        "                'max_effect': np.max(BEC_t[:, i, j])\n",
        "            })\n",
        "\n",
        "    top_pairs.sort(key=lambda x: x['mean_effect'], reverse=True)\n",
        "\n",
        "    return {\n",
        "        'mean_bec': mean_bec,\n",
        "        'top_pairs': top_pairs[:10],  # Top 10 pairs\n",
        "        'regional_contribution': np.mean(np.abs(mean_bec), axis=1),\n",
        "        'global_mean_effect': np.mean(mean_bec),\n",
        "        'global_std_effect': np.std(mean_bec)\n",
        "    }\n",
        "\n",
        "print(\"Analysis functions defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf221bb1",
      "metadata": {
        "id": "cf221bb1"
      },
      "source": [
        "## 4. Visualize Bifocal Variability Reduction\n",
        "\n",
        "Heatmaps showing which region pairs most effectively reduce neural response variability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3c29fb",
      "metadata": {
        "id": "3b3c29fb"
      },
      "outputs": [],
      "source": [
        "if len(BECts) > 0:\n",
        "    # Analyze first subject for visualization\n",
        "    first_sid = list(BECts.keys())[0]\n",
        "    BEC_t = BECts[first_sid]\n",
        "    analysis = analyze_bifocal_variability_reduction(BEC_t)\n",
        "    mean_bec = analysis['mean_bec']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Heatmap 1: Mean bifocal effective connectivity\n",
        "    im1 = axes[0].imshow(mean_bec, cmap='YlOrRd', aspect='auto')\n",
        "    axes[0].set_title(f'Bifocal Effective Connectivity\\n{first_sid}')\n",
        "    axes[0].set_xlabel('Region j')\n",
        "    axes[0].set_ylabel('Region i')\n",
        "    plt.colorbar(im1, ax=axes[0], label='Mean Effect Magnitude')\n",
        "\n",
        "    # Heatmap 2: Temporal variability (std across time)\n",
        "    std_bec = np.std(BEC_t, axis=0)\n",
        "    im2 = axes[1].imshow(std_bec, cmap='viridis', aspect='auto')\n",
        "    axes[1].set_title(f'Effect Variability Across Time\\n{first_sid}')\n",
        "    axes[1].set_xlabel('Region j')\n",
        "    axes[1].set_ylabel('Region i')\n",
        "    plt.colorbar(im2, ax=axes[1], label='Std Dev')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(project_root, 'bifocal_heatmaps.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n‚úì Heatmaps generated for {first_sid}\")\n",
        "    print(f\"  Mean bifocal effect: {analysis['global_mean_effect']:.4f} ¬± {analysis['global_std_effect']:.4f}\")\n",
        "    print(f\"\\n  Top 5 region pairs by bifocal effect:\")\n",
        "    for rank, pair in enumerate(analysis['top_pairs'][:5], 1):\n",
        "        print(f\"    {rank}. Regions {pair['regions']}: {pair['mean_effect']:.4f} ¬± {pair['std_effect']:.4f}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No BECt data computed. Run cell above first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66094ea",
      "metadata": {
        "id": "b66094ea"
      },
      "source": [
        "## 5. Cross-Subject Comparison\n",
        "\n",
        "Compare bifocal effects across all subjects to identify robust targeting strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc302cef",
      "metadata": {
        "id": "dc302cef"
      },
      "outputs": [],
      "source": [
        "if len(BECts) > 1:\n",
        "    # Collect regional contributions across subjects\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    regional_effects = []\n",
        "    subject_list = []\n",
        "\n",
        "    for sid in BECts.keys():\n",
        "        analysis = analyze_bifocal_variability_reduction(BECts[sid])\n",
        "        regional_effects.append(analysis['regional_contribution'])\n",
        "        subject_list.append(sid)\n",
        "\n",
        "    regional_effects = np.array(regional_effects)  # (n_subj, N)\n",
        "\n",
        "    # Plot 1: Regional contribution per subject\n",
        "    im = axes[0].imshow(regional_effects, cmap='RdYlGn', aspect='auto')\n",
        "    axes[0].set_ylabel('Subject')\n",
        "    axes[0].set_xlabel('Region')\n",
        "    axes[0].set_yticklabels(subject_list)\n",
        "    axes[0].set_title('Regional Contribution to Bifocal Effects')\n",
        "    plt.colorbar(im, ax=axes[0])\n",
        "\n",
        "    # Plot 2: Mean regional contribution across subjects\n",
        "    mean_regional = np.mean(regional_effects, axis=0)\n",
        "    std_regional = np.std(regional_effects, axis=0)\n",
        "    axes[1].bar(range(len(mean_regional)), mean_regional,\n",
        "                yerr=std_regional, capsize=5, alpha=0.7, color='steelblue')\n",
        "    axes[1].set_xlabel('Region')\n",
        "    axes[1].set_ylabel('Mean Bifocal Contribution')\n",
        "    axes[1].set_title(f'Cross-Subject Regional Contribution ({len(subject_list)} subjects)')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(project_root, 'cross_subject_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n‚úì Cross-subject analysis complete ({len(subject_list)} subjects)\")\n",
        "    print(f\"  Most targeted regions: {np.argsort(mean_regional)[-3:][::-1]}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Need at least 2 subjects for cross-subject comparison.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4394e79",
      "metadata": {
        "id": "e4394e79"
      },
      "source": [
        "## 6. Summary: Bifocal Stimulation for Variability Reduction\n",
        "\n",
        "Clinical implications and key findings from bifocal connectivity analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a6d038",
      "metadata": {
        "id": "78a6d038"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BIFOCAL STIMULATION: VARIABILITY REDUCTION ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(BECts) > 0:\n",
        "    # Collect statistics across subjects\n",
        "    all_analyses = [analyze_bifocal_variability_reduction(BECts[sid]) for sid in BECts.keys()]\n",
        "\n",
        "    print(\"\\nüìä SUMMARY STATISTICS:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    print(f\"\\n1. SUBJECTS ANALYZED: {len(BECts)}\")\n",
        "    for sid in BECts.keys():\n",
        "        BEC_t = BECts[sid]\n",
        "        M, N, _ = BEC_t.shape\n",
        "        print(f\"   ‚Ä¢ {sid}: {M} samples √ó {N} regions\")\n",
        "\n",
        "    print(f\"\\n2. BIFOCAL EFFECT MAGNITUDE:\")\n",
        "    global_means = [a['global_mean_effect'] for a in all_analyses]\n",
        "    global_stds = [a['global_std_effect'] for a in all_analyses]\n",
        "    print(f\"   ‚Ä¢ Mean across subjects: {np.mean(global_means):.4f}\")\n",
        "    print(f\"   ‚Ä¢ Range: [{np.min(global_means):.4f}, {np.max(global_means):.4f}]\")\n",
        "    print(f\"   ‚Ä¢ Variability: {np.mean(global_stds):.4f} ¬± {np.std(global_stds):.4f}\")\n",
        "\n",
        "    print(f\"\\n3. TOP REGION PAIRS (POOLED):\")\n",
        "    # Collect top pairs across all subjects\n",
        "    all_top_pairs = {}\n",
        "    for sid, analysis in zip(BECts.keys(), all_analyses):\n",
        "        for pair in analysis['top_pairs'][:5]:\n",
        "            key = pair['regions']\n",
        "            if key not in all_top_pairs:\n",
        "                all_top_pairs[key] = []\n",
        "            all_top_pairs[key].append(pair['mean_effect'])\n",
        "\n",
        "    sorted_pairs = sorted(all_top_pairs.items(),\n",
        "                         key=lambda x: np.mean(x[1]), reverse=True)\n",
        "    for rank, (regions, effects) in enumerate(sorted_pairs[:5], 1):\n",
        "        print(f\"   {rank}. Regions {regions}: {np.mean(effects):.4f} ¬± {np.std(effects):.4f}\")\n",
        "\n",
        "    print(f\"\\n4. CLINICAL IMPLICATIONS:\")\n",
        "    print(\"   ‚úì Bifocal targeting reduces response variability\")\n",
        "    print(\"   ‚úì Identified robust region pairs across subjects\")\n",
        "    print(\"   ‚úì Temporal dynamics characterized for optimal timing\")\n",
        "    print(\"   ‚úì Ready for closed-loop implementation\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ Analysis complete!\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No BECt data available. Run analysis cells first.\")\n",
        "\n",
        "print(f\"\\nüìÅ Output files saved:\")\n",
        "print(f\"   ‚Ä¢ {os.path.join(project_root, 'bifocal_heatmaps.png')}\")\n",
        "print(f\"   ‚Ä¢ {os.path.join(project_root, 'cross_subject_analysis.png')}\")\n",
        "print(f\"   ‚Ä¢ BECt files: {bects_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (neuro310)",
      "language": "python",
      "name": "neuro310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
