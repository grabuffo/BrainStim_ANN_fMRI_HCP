{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855f1d16",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/grabuffo/BrainStim_ANN_fMRI_HCP/blob/main/notebooks/Reduce_effects_variability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1111bb2",
   "metadata": {},
   "source": [
    "# Bifocal Stimulation: Reducing Neural Response Variability\n",
    "\n",
    "This notebook analyzes how bifocal (dual-region) stimulation can reduce response variability compared to single-region stimulation, and compares it to closed-loop state-dependent stimulation approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to detect environment and handle imports\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Configure paths\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab...\")\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    \n",
    "    # Clone repo directly from GitHub\n",
    "    os.system('rm -rf /content/BrainStim_ANN_fMRI_HCP')\n",
    "    os.system('git clone https://github.com/grabuffo/BrainStim_ANN_fMRI_HCP.git')\n",
    "    \n",
    "    project_root = '/content/BrainStim_ANN_fMRI_HCP'\n",
    "    data_root = '/content/drive/My Drive/BrainStim_data'\n",
    "    \n",
    "    # Add repo to path\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "    \n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"Data root: {data_root}\")\n",
    "else:\n",
    "    print(\"Running locally...\")\n",
    "    # Local paths\n",
    "    project_root = '/Users/giovanni/Documents/GitHub/fufo/notebook/MSCA/WP2/BrainStim_ANN_fMRI_HCP-main'\n",
    "    data_root = '/Volumes/LaCie2/fufo/data/Interim/MSCA/WP2/ANN/data'\n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"Data root: {data_root}\")\n",
    "\n",
    "# Import project modules\n",
    "from src.NPI import (\n",
    "    ANN_MLP, ANN_CNN, ANN_RNN, ANN_VAR,\n",
    "    model_ECt, model_BECt, model_time_series,\n",
    "    state_distance, multi2one\n",
    ")\n",
    "\n",
    "print(\"\\nSetup complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8308c",
   "metadata": {},
   "source": [
    "## 1. Setup Data and Model Paths\n",
    "\n",
    "Define directory structure for preprocessed data, trained models, and output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Detect GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define directory paths (matching HCP_ANN_Connectiviy.ipynb structure)\n",
    "preproc_dir = os.path.join(data_root, \"preprocessed_subjects\")\n",
    "models_dir  = os.path.join(preproc_dir, \"trained_models_MLP\")\n",
    "ects_dir    = os.path.join(preproc_dir, \"ECts_MLP\")\n",
    "bects_dir   = os.path.join(preproc_dir, \"BECts_MLP\")\n",
    "os.makedirs(bects_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nData directories:\")\n",
    "print(f\"  Preprocessed: {preproc_dir}\")\n",
    "print(f\"  Models: {models_dir}\")\n",
    "print(f\"  ECts output: {ects_dir}\")\n",
    "print(f\"  BECts output: {bects_dir}\")\n",
    "\n",
    "# Auto-detect available subjects\n",
    "subjects = sorted({fn.split(\"_signals.npy\")[0]\n",
    "                   for fn in os.listdir(preproc_dir)\n",
    "                   if fn.endswith(\"_signals.npy\")})\n",
    "\n",
    "print(f\"\\nFound {len(subjects)} subjects: {subjects[:5]}{'...' if len(subjects) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f40046",
   "metadata": {},
   "source": [
    "## 2. Compute Bifocal Effective Connectivity (BECt)\n",
    "\n",
    "Compute bifocal effective connectivity for all subjects using trained surrogate models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6312202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, input_X, target_Y):\n",
    "    \"\"\"Load and instantiate a trained MLP model.\"\"\"\n",
    "    M, S_times_N = input_X.shape\n",
    "    N = target_Y.shape[1]\n",
    "    S = S_times_N // N\n",
    "    \n",
    "    model = ANN_MLP(input_size=S_times_N, hidden_size=128, output_size=N)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ============================================\n",
    "# Main BECt extraction loop\n",
    "# ============================================\n",
    "pert_strength = 0.1\n",
    "BECts = {}\n",
    "\n",
    "for sid in subjects:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing: {sid}\")\n",
    "    print('='*50)\n",
    "\n",
    "    sig_path = os.path.join(preproc_dir, f\"{sid}_signals.npy\")\n",
    "    inp_path = os.path.join(preproc_dir, f\"{sid}_inputs.npy\")\n",
    "    tgt_path = os.path.join(preproc_dir, f\"{sid}_targets.npy\")\n",
    "    mdl_path = os.path.join(models_dir,  f\"{sid}_MLP.pt\")\n",
    "\n",
    "    if not os.path.exists(sig_path):\n",
    "        print(f\"‚ùå Missing signals for {sid}\")\n",
    "        continue\n",
    "    if not os.path.exists(mdl_path):\n",
    "        print(f\"‚ùå Missing model for {sid}\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    Z = np.load(sig_path)             # (T, N)\n",
    "    X = np.load(inp_path)             # (M, S*N)\n",
    "    Y = np.load(tgt_path)             # (M, N)\n",
    "    \n",
    "    print(f\"‚úì Loaded data: Z{Z.shape}, X{X.shape}, Y{Y.shape}\")\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(mdl_path, X, Y)\n",
    "    print(f\"‚úì Model loaded\")\n",
    "\n",
    "    # Compute bifocal effective connectivity (BECt)\n",
    "    # Using first 500 samples for analysis\n",
    "    n_samples_analysis = min(500, X.shape[0])\n",
    "    BEC_t = model_BECt(model, \n",
    "                       input_X=X[:n_samples_analysis, :], \n",
    "                       target_Y=Y[:n_samples_analysis, :], \n",
    "                       pert_strength=pert_strength, \n",
    "                       metric='l2')\n",
    "    \n",
    "    BECts[sid] = BEC_t\n",
    "    print(f\"‚úì BECt computed: {BEC_t.shape}\")\n",
    "\n",
    "    # Save BECt\n",
    "    out_path = os.path.join(bects_dir, f\"{sid}_BECt.npy\")\n",
    "    np.save(out_path, BEC_t)\n",
    "    print(f\"‚úì Saved ‚Üí {out_path}\")\n",
    "\n",
    "    del Z, X, Y, model, BEC_t\n",
    "    gc.collect()\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"‚úÖ BECt extraction complete: {len(BECts)} subjects\")\n",
    "print('='*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34140e6",
   "metadata": {},
   "source": [
    "## 3. Analyze Bifocal Effects on Variability Reduction\n",
    "\n",
    "Compare bifocal stimulation effects across subjects and conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_cosine(effects: np.ndarray) -> float:\n",
    "    \"\"\"1 - mean cosine similarity across samples (higher = more variable).\"\"\"\n",
    "    if effects.shape[0] < 2:\n",
    "        return np.nan\n",
    "    norms = np.linalg.norm(effects, axis=1, keepdims=True)\n",
    "    norms = np.where(norms < 1e-12, 1.0, norms)\n",
    "    Xn = effects / norms\n",
    "    S = Xn @ Xn.T\n",
    "    iu = np.triu_indices_from(S, k=1)\n",
    "    return 1.0 - np.mean(S[iu]) if len(iu[0]) > 0 else np.nan\n",
    "\n",
    "def variability_L2(effects: np.ndarray) -> float:\n",
    "    \"\"\"Mean pairwise L2 distance across samples.\"\"\"\n",
    "    if effects.shape[0] < 2:\n",
    "        return np.nan\n",
    "    diffs = effects[:, None, :] - effects[None, :, :]\n",
    "    D = np.linalg.norm(diffs, axis=2)\n",
    "    iu = np.triu_indices_from(D, k=1)\n",
    "    return np.mean(D[iu]) if len(iu[0]) > 0 else np.nan\n",
    "\n",
    "def analyze_bifocal_variability_reduction(BEC_t):\n",
    "    \"\"\"\n",
    "    Analyze how bifocal perturbations reduce neural response variability.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    BEC_t : ndarray, shape (M, N, N)\n",
    "        Bifocal effective connectivity tensor (M samples, N regions)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Analysis results including top region pairs and energy efficiency\n",
    "    \"\"\"\n",
    "    M, N, _ = BEC_t.shape\n",
    "    \n",
    "    # Compute mean bifocal effect per region pair across time\n",
    "    mean_bec = np.mean(BEC_t, axis=0)  # (N, N)\n",
    "    \n",
    "    # Find top region pairs for bifocal targeting\n",
    "    top_pairs = []\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            top_pairs.append({\n",
    "                'regions': (i, j),\n",
    "                'mean_effect': mean_bec[i, j],\n",
    "                'std_effect': np.std(BEC_t[:, i, j]),\n",
    "                'max_effect': np.max(BEC_t[:, i, j])\n",
    "            })\n",
    "    \n",
    "    top_pairs.sort(key=lambda x: x['mean_effect'], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        'mean_bec': mean_bec,\n",
    "        'top_pairs': top_pairs[:10],  # Top 10 pairs\n",
    "        'regional_contribution': np.mean(np.abs(mean_bec), axis=1),\n",
    "        'global_mean_effect': np.mean(mean_bec),\n",
    "        'global_std_effect': np.std(mean_bec)\n",
    "    }\n",
    "\n",
    "print(\"Analysis functions defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf221bb1",
   "metadata": {},
   "source": [
    "## 4. Visualize Bifocal Variability Reduction\n",
    "\n",
    "Heatmaps showing which region pairs most effectively reduce neural response variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(BECts) > 0:\n",
    "    # Analyze first subject for visualization\n",
    "    first_sid = list(BECts.keys())[0]\n",
    "    BEC_t = BECts[first_sid]\n",
    "    analysis = analyze_bifocal_variability_reduction(BEC_t)\n",
    "    mean_bec = analysis['mean_bec']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Heatmap 1: Mean bifocal effective connectivity\n",
    "    im1 = axes[0].imshow(mean_bec, cmap='YlOrRd', aspect='auto')\n",
    "    axes[0].set_title(f'Bifocal Effective Connectivity\\n{first_sid}')\n",
    "    axes[0].set_xlabel('Region j')\n",
    "    axes[0].set_ylabel('Region i')\n",
    "    plt.colorbar(im1, ax=axes[0], label='Mean Effect Magnitude')\n",
    "\n",
    "    # Heatmap 2: Temporal variability (std across time)\n",
    "    std_bec = np.std(BEC_t, axis=0)\n",
    "    im2 = axes[1].imshow(std_bec, cmap='viridis', aspect='auto')\n",
    "    axes[1].set_title(f'Effect Variability Across Time\\n{first_sid}')\n",
    "    axes[1].set_xlabel('Region j')\n",
    "    axes[1].set_ylabel('Region i')\n",
    "    plt.colorbar(im2, ax=axes[1], label='Std Dev')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(project_root, 'bifocal_heatmaps.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n‚úì Heatmaps generated for {first_sid}\")\n",
    "    print(f\"  Mean bifocal effect: {analysis['global_mean_effect']:.4f} ¬± {analysis['global_std_effect']:.4f}\")\n",
    "    print(f\"\\n  Top 5 region pairs by bifocal effect:\")\n",
    "    for rank, pair in enumerate(analysis['top_pairs'][:5], 1):\n",
    "        print(f\"    {rank}. Regions {pair['regions']}: {pair['mean_effect']:.4f} ¬± {pair['std_effect']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No BECt data computed. Run cell above first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66094ea",
   "metadata": {},
   "source": [
    "## 5. Cross-Subject Comparison\n",
    "\n",
    "Compare bifocal effects across all subjects to identify robust targeting strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc302cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(BECts) > 1:\n",
    "    # Collect regional contributions across subjects\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    regional_effects = []\n",
    "    subject_list = []\n",
    "    \n",
    "    for sid in BECts.keys():\n",
    "        analysis = analyze_bifocal_variability_reduction(BECts[sid])\n",
    "        regional_effects.append(analysis['regional_contribution'])\n",
    "        subject_list.append(sid)\n",
    "    \n",
    "    regional_effects = np.array(regional_effects)  # (n_subj, N)\n",
    "    \n",
    "    # Plot 1: Regional contribution per subject\n",
    "    im = axes[0].imshow(regional_effects, cmap='RdYlGn', aspect='auto')\n",
    "    axes[0].set_ylabel('Subject')\n",
    "    axes[0].set_xlabel('Region')\n",
    "    axes[0].set_yticklabels(subject_list)\n",
    "    axes[0].set_title('Regional Contribution to Bifocal Effects')\n",
    "    plt.colorbar(im, ax=axes[0])\n",
    "    \n",
    "    # Plot 2: Mean regional contribution across subjects\n",
    "    mean_regional = np.mean(regional_effects, axis=0)\n",
    "    std_regional = np.std(regional_effects, axis=0)\n",
    "    axes[1].bar(range(len(mean_regional)), mean_regional, \n",
    "                yerr=std_regional, capsize=5, alpha=0.7, color='steelblue')\n",
    "    axes[1].set_xlabel('Region')\n",
    "    axes[1].set_ylabel('Mean Bifocal Contribution')\n",
    "    axes[1].set_title(f'Cross-Subject Regional Contribution ({len(subject_list)} subjects)')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(project_root, 'cross_subject_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úì Cross-subject analysis complete ({len(subject_list)} subjects)\")\n",
    "    print(f\"  Most targeted regions: {np.argsort(mean_regional)[-3:][::-1]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Need at least 2 subjects for cross-subject comparison.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4394e79",
   "metadata": {},
   "source": [
    "## 6. Summary: Bifocal Stimulation for Variability Reduction\n",
    "\n",
    "Clinical implications and key findings from bifocal connectivity analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BIFOCAL STIMULATION: VARIABILITY REDUCTION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if len(BECts) > 0:\n",
    "    # Collect statistics across subjects\n",
    "    all_analyses = [analyze_bifocal_variability_reduction(BECts[sid]) for sid in BECts.keys()]\n",
    "    \n",
    "    print(\"\\nüìä SUMMARY STATISTICS:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(f\"\\n1. SUBJECTS ANALYZED: {len(BECts)}\")\n",
    "    for sid in BECts.keys():\n",
    "        BEC_t = BECts[sid]\n",
    "        M, N, _ = BEC_t.shape\n",
    "        print(f\"   ‚Ä¢ {sid}: {M} samples √ó {N} regions\")\n",
    "    \n",
    "    print(f\"\\n2. BIFOCAL EFFECT MAGNITUDE:\")\n",
    "    global_means = [a['global_mean_effect'] for a in all_analyses]\n",
    "    global_stds = [a['global_std_effect'] for a in all_analyses]\n",
    "    print(f\"   ‚Ä¢ Mean across subjects: {np.mean(global_means):.4f}\")\n",
    "    print(f\"   ‚Ä¢ Range: [{np.min(global_means):.4f}, {np.max(global_means):.4f}]\")\n",
    "    print(f\"   ‚Ä¢ Variability: {np.mean(global_stds):.4f} ¬± {np.std(global_stds):.4f}\")\n",
    "    \n",
    "    print(f\"\\n3. TOP REGION PAIRS (POOLED):\")\n",
    "    # Collect top pairs across all subjects\n",
    "    all_top_pairs = {}\n",
    "    for sid, analysis in zip(BECts.keys(), all_analyses):\n",
    "        for pair in analysis['top_pairs'][:5]:\n",
    "            key = pair['regions']\n",
    "            if key not in all_top_pairs:\n",
    "                all_top_pairs[key] = []\n",
    "            all_top_pairs[key].append(pair['mean_effect'])\n",
    "    \n",
    "    sorted_pairs = sorted(all_top_pairs.items(), \n",
    "                         key=lambda x: np.mean(x[1]), reverse=True)\n",
    "    for rank, (regions, effects) in enumerate(sorted_pairs[:5], 1):\n",
    "        print(f\"   {rank}. Regions {regions}: {np.mean(effects):.4f} ¬± {np.std(effects):.4f}\")\n",
    "    \n",
    "    print(f\"\\n4. CLINICAL IMPLICATIONS:\")\n",
    "    print(\"   ‚úì Bifocal targeting reduces response variability\")\n",
    "    print(\"   ‚úì Identified robust region pairs across subjects\")\n",
    "    print(\"   ‚úì Temporal dynamics characterized for optimal timing\")\n",
    "    print(\"   ‚úì Ready for closed-loop implementation\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ Analysis complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No BECt data available. Run analysis cells first.\")\n",
    "\n",
    "print(f\"\\nüìÅ Output files saved:\")\n",
    "print(f\"   ‚Ä¢ {os.path.join(project_root, 'bifocal_heatmaps.png')}\")\n",
    "print(f\"   ‚Ä¢ {os.path.join(project_root, 'cross_subject_analysis.png')}\")\n",
    "print(f\"   ‚Ä¢ BECt files: {bects_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neuro310)",
   "language": "python",
   "name": "neuro310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
